{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio, torchvision.transforms as transforms, matplotlib.pyplot as plt, torch.nn as nn, torch.optim as optim, numpy as np\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import  StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, auc, classification_report, roc_auc_score\n",
    "from torch.autograd import grad\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "cuda1 = torch.device(\"cuda:1\")\n",
    "device = cuda1\n",
    "print(torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"No GPU available\")\n",
    "data = np.load(\"../../hvcm/RFQ.npy\", allow_pickle=True)\n",
    "label = np.load(\"../../hvcm/RFQ_labels.npy\", allow_pickle=True)\n",
    "label = label[:, 1]  # Assuming the second column is the label\n",
    "label = (label == \"Fault\").astype(int)  # Convert to binary labels\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "normal_data = data[label == 0]\n",
    "faulty_data = data[label == 1]\n",
    "\n",
    "normal_label = label[label == 0]\n",
    "faulty_label = label[label == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14127475",
   "metadata": {},
   "source": [
    "# Multivariate Anomaly Detection GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18b3e2",
   "metadata": {},
   "source": [
    "Rewrite, because MADGAN use LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Generator with better architecture\n",
    "class MADGeneratorEnhanced(nn.Module):\n",
    "    def __init__(self, latent_dim=100, hidden_dim=128, num_features=14, seq_len=4500):\n",
    "        super(MADGeneratorEnhanced, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_features = num_features\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        # Multi-layer LSTM for better temporal modeling\n",
    "        self.lstm1 = nn.LSTM(latent_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        # Feature projection layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, num_features),\n",
    "            nn.Tanh()  # Bounded output\n",
    "        )\n",
    "        \n",
    "        # Batch normalization for stability\n",
    "        self.bn = nn.BatchNorm1d(seq_len)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # z shape: (batch_size, seq_len, latent_dim)\n",
    "        h1, _ = self.lstm1(z)\n",
    "        h2, _ = self.lstm2(h1)\n",
    "        \n",
    "        # Apply batch norm across sequence dimension\n",
    "        h2_norm = self.bn(h2)\n",
    "        \n",
    "        # Project to feature space\n",
    "        out = self.fc_layers(h2_norm)\n",
    "        return out\n",
    "\n",
    "# Enhanced Discriminator with better architecture\n",
    "class MADDiscriminatorEnhanced(nn.Module):\n",
    "    def __init__(self, num_features=14, hidden_dim=128, seq_len=4500):\n",
    "        super(MADDiscriminatorEnhanced, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Multi-layer LSTM for better temporal understanding\n",
    "        self.lstm1 = nn.LSTM(num_features, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        # Attention mechanism for better sequence processing\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)\n",
    "        \n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 4, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, num_features)\n",
    "        h1, _ = self.lstm1(x)\n",
    "        h2, _ = self.lstm2(h1)\n",
    "        \n",
    "        # Apply attention\n",
    "        attn_out, _ = self.attention(h2, h2, h2)\n",
    "        \n",
    "        # Global average pooling across sequence\n",
    "        pooled = torch.mean(attn_out, dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        out = self.classifier(pooled)\n",
    "        return out\n",
    "\n",
    "# Enhanced training function\n",
    "def train_mad_gan_enhanced(normal_data, device, epochs=30, batch_size=32, lr_g=0.0002, lr_d=0.0001):\n",
    "    \"\"\"\n",
    "    Enhanced MAD-GAN training with improved stability\n",
    "    \"\"\"\n",
    "    # Data preprocessing\n",
    "    print(f\"Original data shape: {normal_data.shape}\")\n",
    "    print(f\"Data range: [{normal_data.min():.4f}, {normal_data.max():.4f}]\")\n",
    "    \n",
    "    # Normalize data to [-1, 1] range for tanh output\n",
    "    data_min = normal_data.min()\n",
    "    data_max = normal_data.max()\n",
    "    normalized_data = 2 * (normal_data - data_min) / (data_max - data_min) - 1\n",
    "    print(f\"Normalized data range: [{normalized_data.min():.4f}, {normalized_data.max():.4f}]\")\n",
    "    \n",
    "    # Model parameters\n",
    "    latent_dim = 100\n",
    "    hidden_dim = 128\n",
    "    num_features = normalized_data.shape[-1]  # 14\n",
    "    seq_len = normalized_data.shape[1]  # 4500\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = MADGeneratorEnhanced(latent_dim, hidden_dim, num_features, seq_len).to(device)\n",
    "    discriminator = MADDiscriminatorEnhanced(num_features, hidden_dim, seq_len).to(device)\n",
    "    \n",
    "    # Enhanced weight initialization\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, (nn.LSTM)):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.orthogonal_(param)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    generator.apply(weights_init)\n",
    "    discriminator.apply(weights_init)\n",
    "    \n",
    "    # Optimizers with proper learning rates\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataset = TensorDataset(torch.tensor(normalized_data, dtype=torch.float32))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    print(\"Starting Enhanced MAD-GAN training...\")\n",
    "    print(f\"Learning rates - Generator: {lr_g}, Discriminator: {lr_d}\")\n",
    "    \n",
    "    # Training history\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_d_losses = []\n",
    "        epoch_g_losses = []\n",
    "        \n",
    "        for i, (real_data,) in enumerate(dataloader):\n",
    "            real_data = real_data.to(device)\n",
    "            current_batch_size = real_data.size(0)\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(current_batch_size, 1, device=device)\n",
    "            fake_labels = torch.zeros(current_batch_size, 1, device=device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real data\n",
    "            real_pred = discriminator(real_data)\n",
    "            d_real_loss = criterion(real_pred, real_labels)\n",
    "            \n",
    "            # Fake data\n",
    "            z = torch.randn(current_batch_size, seq_len, latent_dim, device=device)\n",
    "            fake_data = generator(z)\n",
    "            fake_pred = discriminator(fake_data.detach())\n",
    "            d_fake_loss = criterion(fake_pred, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1.0)\n",
    "            \n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # Train Generator every 2 discriminator updates\n",
    "            if i % 2 == 0:\n",
    "                optimizer_G.zero_grad()\n",
    "                \n",
    "                # Generate new fake data\n",
    "                z = torch.randn(current_batch_size, seq_len, latent_dim, device=device)\n",
    "                fake_data = generator(z)\n",
    "                fake_pred = discriminator(fake_data)\n",
    "                \n",
    "                # Generator loss (wants discriminator to classify fake as real)\n",
    "                g_loss = criterion(fake_pred, real_labels)\n",
    "                g_loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(generator.parameters(), 1.0)\n",
    "                \n",
    "                optimizer_G.step()\n",
    "                \n",
    "                epoch_g_losses.append(g_loss.item())\n",
    "            \n",
    "            epoch_d_losses.append(d_loss.item())\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_d_loss = np.mean(epoch_d_losses)\n",
    "        avg_g_loss = np.mean(epoch_g_losses) if epoch_g_losses else 0\n",
    "        \n",
    "        d_losses.append(avg_d_loss)\n",
    "        g_losses.append(avg_g_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f}\")\n",
    "        \n",
    "        # Monitor training stability\n",
    "        if len(d_losses) >= 5:\n",
    "            recent_d_std = np.std(d_losses[-5:])\n",
    "            recent_g_std = np.std(g_losses[-5:]) if len(g_losses) >= 5 else 0\n",
    "            \n",
    "            if recent_d_std < 0.1 and recent_g_std < 0.1:\n",
    "                print(\"  ✅ Training highly stable\")\n",
    "            elif recent_d_std < 0.2 and recent_g_std < 0.2:\n",
    "                print(\"  🔄 Training moderately stable\")\n",
    "            else:\n",
    "                print(\"  ⚠️  Training showing some instability\")\n",
    "    \n",
    "    return generator, discriminator, d_losses, g_losses, (data_min, data_max)\n",
    "\n",
    "# Enhanced sample generation\n",
    "def generate_samples_enhanced(generator, num_samples, seq_len, latent_dim, device, data_range):\n",
    "    \"\"\"\n",
    "    Generate samples with proper denormalization\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    data_min, data_max = data_range\n",
    "    \n",
    "    generated_batches = []\n",
    "    batch_size = 32\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            current_batch_size = end - start\n",
    "            \n",
    "            z = torch.randn(current_batch_size, seq_len, latent_dim, device=device)\n",
    "            batch_generated = generator(z)\n",
    "            \n",
    "            # Denormalize from [-1, 1] back to original range\n",
    "            batch_generated = (batch_generated + 1) / 2 * (data_max - data_min) + data_min\n",
    "            \n",
    "            generated_batches.append(batch_generated.cpu())\n",
    "    \n",
    "    return torch.cat(generated_batches, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dd307",
   "metadata": {},
   "source": [
    "# Multivariate Anomaly Detection GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0267ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Clear GPU memory\n",
    "\n",
    "# Enhanced training with balanced learning rates\n",
    "generator, discriminator, d_history, g_history, data_range = train_mad_gan_enhanced(\n",
    "    normal_data, \n",
    "    device, \n",
    "    epochs=50,\n",
    "    batch_size=16,      # Smaller batch for stability\n",
    "    lr_g=0.0002,        # Balanced learning rate\n",
    "    lr_d=0.0001         # 2:1 ratio\n",
    ")\n",
    "\n",
    "# Generate synthetic samples\n",
    "num_samples = len(normal_data)\n",
    "seq_len = normal_data.shape[1]\n",
    "latent_dim = 100\n",
    "\n",
    "generated_data = generate_samples_enhanced(\n",
    "    generator, num_samples, seq_len, latent_dim, device, data_range\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(d_history, label='Discriminator')\n",
    "plt.title('Discriminator Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(g_history, label='Generator')\n",
    "plt.title('Generator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ee542",
   "metadata": {},
   "source": [
    "# Generate and Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6809752",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "\n",
    "num_samples = len(data[label == 0])  # Number of synthetic samples to generate\n",
    "batch_size = 16  # Reduce batch size to avoid OOM\n",
    "seq_len = 4500\n",
    "\n",
    "generated_batches = []\n",
    "with torch.no_grad():\n",
    "    for start in range(0, num_samples, batch_size):\n",
    "        end = min(start + batch_size, num_samples)\n",
    "        current_batch_size = end - start\n",
    "        z = torch.randn(current_batch_size, seq_len, latent_dim, device=device)\n",
    "        batch_generated = generator(z)\n",
    "        generated_batches.append(batch_generated.cpu())  # Move to CPU to save GPU memory\n",
    "\n",
    "generated_data = torch.cat(generated_batches, dim=0).numpy()\n",
    "\n",
    "# Combine with real data\n",
    "combine_data_normal = np.concatenate((generated_data, normal_data), axis=0)\n",
    "combine_labels_normal = np.concatenate((np.zeros(num_samples), normal_label), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21901a15",
   "metadata": {},
   "source": [
    "# Processing: Mel Spec > Resizing > Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01061dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_spectrogram(spectrogram, global_min=None, global_max=None):\n",
    "    \"\"\"\n",
    "    Improved spectrogram processing with consistent normalization\n",
    "    \"\"\"\n",
    "    # Use global min/max for consistent normalization across all spectrograms\n",
    "    if global_min is not None and global_max is not None:\n",
    "        spectrogram = (spectrogram - global_min) / (global_max - global_min + 1e-8)\n",
    "    else:\n",
    "        spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min() + 1e-8)\n",
    "    \n",
    "    # Clip to [0,1] and convert to uint8\n",
    "    spectrogram = np.clip(spectrogram, 0, 1)\n",
    "    spectrogram = np.uint8(spectrogram.cpu().numpy() * 255)\n",
    "    spectrogram = np.stack([spectrogram] * 3, axis=-1)\n",
    "    \n",
    "    image = Image.fromarray(spectrogram)\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "def process_dataset_improved(data, sample_rate=1000):  # More reasonable sample rate\n",
    "    \"\"\"\n",
    "    Improved dataset processing with better mel-spectrogram parameters\n",
    "    \"\"\"\n",
    "    num_samples, seq_len, num_channels = data.shape\n",
    "    features = np.zeros((num_samples, num_channels, 4096))\n",
    "    \n",
    "    # Better mel-spectrogram parameters for sensor data\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=128,\n",
    "        n_fft=512,          # Reasonable FFT size\n",
    "        hop_length=256,     # 50% overlap\n",
    "        win_length=512,\n",
    "        window_fn=torch.hann_window\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load VGG16 model\n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device)\n",
    "    model.classifier = model.classifier[:-3]\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute global min/max for consistent normalization\n",
    "    print(\"Computing global spectrogram statistics...\")\n",
    "    all_mels = []\n",
    "    for i in range(min(100, num_samples)):  # Sample subset for statistics\n",
    "        for j in range(num_channels):\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            all_mels.append(mel.cpu().numpy())\n",
    "    \n",
    "    all_mels = np.concatenate([mel.flatten() for mel in all_mels])\n",
    "    global_min, global_max = np.percentile(all_mels, [1, 99])  # Use percentiles to avoid outliers\n",
    "    \n",
    "    print(f\"Processing {num_samples} samples...\")\n",
    "    for i in range(num_samples):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{num_samples} samples\")\n",
    "            \n",
    "        for j in range(num_channels):\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            \n",
    "            # Use consistent normalization\n",
    "            img = resize_spectrogram(mel, global_min, global_max)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                feat = model(img.unsqueeze(0).to(device))\n",
    "            features[i, j, :] = feat.squeeze().cpu().numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Alternative: Multi-channel processing\n",
    "def process_dataset_multichannel(data, sample_rate=1000):\n",
    "    \"\"\"\n",
    "    Process multiple channels together to capture cross-channel relationships\n",
    "    \"\"\"\n",
    "    num_samples, seq_len, num_channels = data.shape\n",
    "    features = np.zeros((num_samples, 4096))  # Single feature vector per sample\n",
    "    \n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=128,\n",
    "        n_fft=512,\n",
    "        hop_length=256,\n",
    "        win_length=512\n",
    "    ).to(device)\n",
    "    \n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device)\n",
    "    model.classifier = model.classifier[:-3]\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Processing {num_samples} samples with multi-channel approach...\")\n",
    "    for i in range(num_samples):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{num_samples} samples\")\n",
    "        \n",
    "        # Combine multiple channels into RGB image\n",
    "        channel_spectrograms = []\n",
    "        for j in range(min(3, num_channels)):  # Use first 3 channels as RGB\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            \n",
    "            # Normalize each channel spectrogram\n",
    "            mel_norm = (mel - mel.min()) / (mel.max() - mel.min() + 1e-8)\n",
    "            mel_resized = torch.nn.functional.interpolate(\n",
    "                mel_norm.unsqueeze(0).unsqueeze(0), \n",
    "                size=(224, 224), \n",
    "                mode='bilinear'\n",
    "            ).squeeze()\n",
    "            channel_spectrograms.append(mel_resized.cpu().numpy())\n",
    "        \n",
    "        # Stack as RGB image\n",
    "        if len(channel_spectrograms) == 1:\n",
    "            rgb_img = np.stack([channel_spectrograms[0]] * 3, axis=0)\n",
    "        elif len(channel_spectrograms) == 2:\n",
    "            rgb_img = np.stack([channel_spectrograms[0], channel_spectrograms[1], channel_spectrograms[0]], axis=0)\n",
    "        else:\n",
    "            rgb_img = np.stack(channel_spectrograms[:3], axis=0)\n",
    "        \n",
    "        img_tensor = torch.tensor(rgb_img, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            feat = model(img_tensor)\n",
    "        features[i, :] = feat.squeeze().cpu().numpy()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f39ba8",
   "metadata": {},
   "source": [
    "# AE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size=4096):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 64), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 8), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 4), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 16), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, input_size), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "# Train autoencoder\n",
    "def train_autoencoder(features, epochs=20, batch_size=128):\n",
    "    x = torch.tensor(features.reshape(-1, 4096), dtype=torch.float32).to(device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=batch_size, shuffle=True)\n",
    "    model = Autoencoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)  # Add weight decay\n",
    "    criterion = nn.MSELoss()  # Try MSE instead of L1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            # Add noise for denoising autoencoder\n",
    "            noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "            outputs = model(noisy_inputs)\n",
    "            loss = criterion(outputs, inputs)  # Reconstruct clean from noisy\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.6f}\")\n",
    "    return model\n",
    "\n",
    "# Compute reconstruction errors\n",
    "def compute_reconstruction_loss(model, data, add_noise=True):\n",
    "    \"\"\"\n",
    "    Compute reconstruction loss per sample (not per segment)\n",
    "    data: shape (n_samples, n_channels, 4096)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    n_samples, n_channels, n_features = data.shape\n",
    "    sample_errors = []\n",
    "    \n",
    "    # Flatten to (n_samples*n_channels, 4096) for batch processing\n",
    "    x = torch.tensor(data.reshape(-1, n_features), dtype=torch.float32).to(next(model.parameters()).device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=64)\n",
    "    \n",
    "    all_errors = []\n",
    "    criterion = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            \n",
    "            if add_noise:\n",
    "                noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "                outputs = model(noisy_inputs)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            # Per-segment reconstruction error\n",
    "            segment_errors = criterion(outputs, inputs).mean(dim=1)\n",
    "            all_errors.extend(segment_errors.cpu().numpy())\n",
    "    \n",
    "    # Reshape back to (n_samples, n_channels) and aggregate per sample\n",
    "    all_errors = np.array(all_errors).reshape(n_samples, n_channels)\n",
    "    sample_errors = all_errors.mean(axis=1)  # Average across channels per sample\n",
    "    \n",
    "    return sample_errors\n",
    "\n",
    "# 2. Find best threshold based on F1 score\n",
    "def find_best_threshold(errors, labels):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        f1 = f1_score(labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "def evaluate_on_test_with_threshold_search(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    X_test: shape (n_samples, 1, 4096) - already has channel dimension added\n",
    "    y_test: shape (n_samples,)\n",
    "    \"\"\"\n",
    "    # X_test already has shape (n_samples, 1, 4096) from your code\n",
    "    # So we can directly compute reconstruction errors\n",
    "    test_errors = compute_reconstruction_loss(model, X_test)\n",
    "    \n",
    "    # Find best threshold based on F1 score\n",
    "    best_threshold = 0\n",
    "    best_f1 = 0\n",
    "    for threshold in np.linspace(test_errors.min(), test_errors.max(), 100):\n",
    "        preds = (test_errors > threshold).astype(int)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    # Predict using best threshold\n",
    "    test_preds = (test_errors > best_threshold).astype(int)\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"Best Threshold = {best_threshold:.6f}, Best F1 Score = {best_f1:.4f}\")\n",
    "    print(\"Evaluation on Test Set:\")\n",
    "    print(\"Accuracy =\", accuracy_score(y_test, test_preds))\n",
    "    print(\"Precision =\", precision_score(y_test, test_preds))\n",
    "    print(\"Recall =\", recall_score(y_test, test_preds))\n",
    "    print(\"F1 Score =\", f1_score(y_test, test_preds))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81797ba0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = np.concatenate((combine_data_normal, data[label == 1]), axis=0)  # Combine real and generated data\n",
    "combine_label = np.concatenate((np.zeros(len(combine_labels_normal)), label[label == 1]), axis=0)  # Labels: 0 for real, 0 for generated\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scaled_normal_data = StandardScaler().fit_transform(combine_data_normal.reshape(-1, combine_data_normal.shape[-1])).reshape(combine_data_normal.shape)\n",
    "scaled_original_data = StandardScaler().fit_transform(data.reshape(-1, data.shape[-1])).reshape(data.shape)\n",
    "features_original = process_dataset_multichannel(scaled_original_data)\n",
    "print(\"Features shape:\", features_original.shape)\n",
    "features_normal = process_dataset_multichannel(scaled_normal_data)\n",
    "print(\"Features shape:\", features_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64ca03",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "prec = []\n",
    "rec = []\n",
    "f1 = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(features_original, label)):\n",
    "    \n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "   # Get full fold data\n",
    "    fold_data, fold_labels = features_original[train_idx], label[train_idx]\n",
    "    val_data, val_labels = features_original[val_idx], label[val_idx]\n",
    "   \n",
    "    # Split into training and validation folds\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(fold_data, fold_labels, test_size=0.2, shuffle=True, random_state=np.random.randint(0, 1000))\n",
    "    X_val, X_test, y_val, y_test = train_test_split(val_data, val_labels, test_size=0.5, shuffle=True, random_state=np.random.randint(0, 1000))\n",
    "\n",
    "\n",
    "    # Train autoencoder on the training fold\n",
    "    model = train_autoencoder(features_normal, epochs=15, batch_size=64)\n",
    "\n",
    "    # Add channel dimension to X_val\n",
    "    X_val = X_val[:, np.newaxis, :]\n",
    "\n",
    "    # Evaluate on validation fold\n",
    "    val_normal = X_val[y_val == 0]\n",
    "    val_abnormal = X_val[y_val == 1]\n",
    "    val_errors_normal = compute_reconstruction_loss(model, val_normal)\n",
    "    val_errors_abnormal = compute_reconstruction_loss(model, val_abnormal)\n",
    "    val_errors = np.concatenate([val_errors_normal, val_errors_abnormal])\n",
    "    y_val_combined = np.concatenate([np.zeros(len(val_errors_normal)), np.ones(len(val_errors_abnormal))])\n",
    "    \n",
    "    threshold, best_f1 = find_best_threshold(val_errors, y_val_combined)\n",
    "    print(f\"Best threshold: {threshold}, Best F1 Score: {best_f1}\")\n",
    "\n",
    "    # Plot histogram of reconstruction errors on both normal and abnormal samples\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(val_errors_normal, bins=50, alpha=0.5, label='Normal Samples', color='blue')\n",
    "    plt.hist(val_errors_abnormal, bins=50, alpha=0.5, label='Abnormal Samples', color='red')\n",
    "    plt.axvline(threshold, color='black', linestyle='--', label='Threshold')\n",
    "    plt.title('Reconstruction Errors on Validation Set')\n",
    "    plt.xlabel('Reconstruction Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    X_test = X_test[:, np.newaxis, :]  # Add channel dimension    \n",
    "    val_errors_test = compute_reconstruction_loss(model, X_test)\n",
    "    # Evaluate on test set\n",
    "    evaluate_on_test_with_threshold_search(model, X_test, y_test)\n",
    "    acc.append(accuracy_score(y_test, (val_errors_test > threshold).astype(int)))\n",
    "    prec.append(precision_score(y_test, (val_errors_test > threshold).astype(int)))\n",
    "    rec.append(recall_score(y_test, (val_errors_test > threshold).astype(int)))\n",
    "    f1.append(f1_score(y_test, (val_errors_test > threshold).astype(int)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25980ecb",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ffa6f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
