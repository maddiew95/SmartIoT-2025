{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio, torchvision.transforms as transforms, matplotlib.pyplot as plt, torch.nn as nn, torch.optim as optim, numpy as np, os\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, auc, classification_report, roc_auc_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from torch.autograd import grad\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "cuda1 = torch.device(\"cuda:1\")\n",
    "device = cuda1\n",
    "print(torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"No GPU available\")\n",
    "data = np.load(\"../../hvcm/RFQ.npy\", allow_pickle=True)\n",
    "label = np.load(\"../../hvcm/RFQ_labels.npy\", allow_pickle=True)\n",
    "label = label[:, 1]  # Assuming the second column is the label\n",
    "label = (label == \"Fault\").astype(int)  # Convert to binary labels\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data.reshape(-1, data.shape[-1])).reshape(data.shape)\n",
    "\n",
    "normal_data = data[label == 0]\n",
    "faulty_data = data[label == 1]\n",
    "\n",
    "normal_label = label[label == 0]\n",
    "faulty_label = label[label == 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normal_data, normal_label, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14127475",
   "metadata": {},
   "source": [
    "# Multivariate Anomaly Detection GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18b3e2",
   "metadata": {},
   "source": [
    "Rewrite, because MADGAN use LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Memory-efficient MAD-GAN Generator\n",
    "class MADGeneratorMemoryEfficient(nn.Module):\n",
    "    def __init__(self, latent_dim=50, hidden_dim=64, num_features=14, seq_len=4500):\n",
    "        super(MADGeneratorMemoryEfficient, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_features = num_features\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        # Single LSTM layer to reduce memory\n",
    "        self.lstm = nn.LSTM(latent_dim, hidden_dim, batch_first=True, dropout=0.1)\n",
    "        \n",
    "        # Simplified projection\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim // 2, num_features),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Process in chunks to save memory\n",
    "        chunk_size = 1000  # Process 1000 timesteps at a time\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(0, self.seq_len, chunk_size):\n",
    "            end_idx = min(i + chunk_size, self.seq_len)\n",
    "            z_chunk = z[:, i:end_idx, :]\n",
    "            \n",
    "            h_chunk, _ = self.lstm(z_chunk)\n",
    "            out_chunk = self.fc(h_chunk)\n",
    "            outputs.append(out_chunk)\n",
    "            \n",
    "            # Clear intermediate results\n",
    "            del h_chunk, z_chunk\n",
    "            \n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "# Memory-efficient MAD-GAN Discriminator\n",
    "class MADDiscriminatorMemoryEfficient(nn.Module):\n",
    "    def __init__(self, num_features=14, hidden_dim=64, seq_len=4500):\n",
    "        super(MADDiscriminatorMemoryEfficient, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        # Single LSTM layer\n",
    "        self.lstm = nn.LSTM(num_features, hidden_dim, batch_first=True, dropout=0.1)\n",
    "        \n",
    "        # Simple pooling and classification\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Process in chunks to save memory\n",
    "        chunk_size = 1000\n",
    "        hidden_states = []\n",
    "        \n",
    "        for i in range(0, self.seq_len, chunk_size):\n",
    "            end_idx = min(i + chunk_size, self.seq_len)\n",
    "            x_chunk = x[:, i:end_idx, :]\n",
    "            \n",
    "            h_chunk, _ = self.lstm(x_chunk)\n",
    "            # Take the last hidden state of each chunk\n",
    "            hidden_states.append(h_chunk[:, -1, :])\n",
    "            \n",
    "            del h_chunk, x_chunk\n",
    "        \n",
    "        # Average the hidden states from all chunks\n",
    "        avg_hidden = torch.stack(hidden_states, dim=1).mean(dim=1)\n",
    "        out = self.classifier(avg_hidden)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Memory-efficient training function with gradient accumulation\n",
    "def train_mad_gan_memory_efficient(normal_data, device, epochs=30, batch_size=2, \n",
    "                                 accumulation_steps=8, lr_g=0.0002, lr_d=0.0001):\n",
    "    \"\"\"\n",
    "    Memory-efficient MAD-GAN training with very small batches and gradient accumulation\n",
    "    \"\"\"\n",
    "    print(f\"Original data shape: {normal_data.shape}\")\n",
    "    print(f\"Data range: [{normal_data.min():.4f}, {normal_data.max():.4f}]\")\n",
    "    \n",
    "    # # Normalize data to [-1, 1] range\n",
    "    # data_min = normal_data.min()\n",
    "    # data_max = normal_data.max()\n",
    "    # normalized_data = 2 * (normal_data - data_min) / (data_max - data_min) - 1\n",
    "    # print(f\"Normalized data range: [{normalized_data.min():.4f}, {normalized_data.max():.4f}]\")\n",
    "    \n",
    "    # Model parameters\n",
    "    latent_dim = 50  # Reduced latent dimension\n",
    "    hidden_dim = 64  # Reduced hidden dimension\n",
    "    num_features = normal_data.shape[-1]\n",
    "    seq_len = normal_data.shape[1]\n",
    "    \n",
    "    print(f\"Model parameters - Latent: {latent_dim}, Hidden: {hidden_dim}, Features: {num_features}, Seq_len: {seq_len}\")\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = MADGeneratorMemoryEfficient(latent_dim, hidden_dim, num_features, seq_len).to(device)\n",
    "    discriminator = MADDiscriminatorMemoryEfficient(num_features, hidden_dim, seq_len).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    g_params = sum(p.numel() for p in generator.parameters())\n",
    "    d_params = sum(p.numel() for p in discriminator.parameters())\n",
    "    print(f\"Generator parameters: {g_params:,}\")\n",
    "    print(f\"Discriminator parameters: {d_params:,}\")\n",
    "    \n",
    "    # Weight initialization\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, nn.LSTM):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.orthogonal_(param)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    generator.apply(weights_init)\n",
    "    discriminator.apply(weights_init)\n",
    "    \n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Create dataloader with very small batch size\n",
    "    dataset = TensorDataset(torch.tensor(normal_data, dtype=torch.float32))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    print(f\"Starting Memory-Efficient MAD-GAN training...\")\n",
    "    print(f\"Batch size: {batch_size}, Accumulation steps: {accumulation_steps}\")\n",
    "    print(f\"Effective batch size: {batch_size * accumulation_steps}\")\n",
    "    print(f\"Learning rates - Generator: {lr_g}, Discriminator: {lr_d}\")\n",
    "    \n",
    "    # Training history\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_d_losses = []\n",
    "        epoch_g_losses = []\n",
    "        \n",
    "        # Initialize accumulators\n",
    "        optimizer_D.zero_grad()\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        for i, (real_data,) in enumerate(dataloader):\n",
    "            real_data = real_data.to(device)\n",
    "            current_batch_size = real_data.size(0)\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(current_batch_size, 1, device=device) * 0.9\n",
    "            fake_labels = torch.zeros(current_batch_size, 1, device=device) + 0.1\n",
    "            \n",
    "            # Train Discriminator\n",
    "            # Real data\n",
    "            real_pred = discriminator(real_data)\n",
    "            d_real_loss = criterion(real_pred, real_labels) / accumulation_steps\n",
    "            d_real_loss.backward()\n",
    "            \n",
    "            # Fake data\n",
    "            z = torch.randn(current_batch_size, seq_len, latent_dim, device=device)\n",
    "            with torch.no_grad():\n",
    "                fake_data = generator(z)\n",
    "            fake_pred = discriminator(fake_data)\n",
    "            d_fake_loss = criterion(fake_pred, fake_labels) / accumulation_steps\n",
    "            d_fake_loss.backward()\n",
    "            \n",
    "            d_loss = (d_real_loss + d_fake_loss) * accumulation_steps\n",
    "            epoch_d_losses.append(d_loss.item())\n",
    "            \n",
    "            # Update discriminator every accumulation_steps\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1.0)\n",
    "                optimizer_D.step()\n",
    "                optimizer_D.zero_grad()\n",
    "            \n",
    "            # Train Generator less frequently\n",
    "            if i % (accumulation_steps * 2) == 0:  # Train G every 2*accumulation_steps\n",
    "                z = torch.randn(current_batch_size, seq_len, latent_dim, device=device)\n",
    "                fake_data = generator(z)\n",
    "                fake_pred = discriminator(fake_data)\n",
    "                \n",
    "                g_loss = criterion(fake_pred, real_labels) / accumulation_steps\n",
    "                g_loss.backward()\n",
    "                \n",
    "                epoch_g_losses.append(g_loss.item() * accumulation_steps)\n",
    "                \n",
    "                if (i + 1) % accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(generator.parameters(), 1.0)\n",
    "                    optimizer_G.step()\n",
    "                    optimizer_G.zero_grad()\n",
    "            \n",
    "            # Clear cache periodically\n",
    "            if i % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # # Memory monitoring\n",
    "            # if i % 50 == 0 and torch.cuda.is_available():\n",
    "            #     memory_used = torch.cuda.memory_allocated(device) / 1024**3\n",
    "            #     memory_cached = torch.cuda.memory_reserved(device) / 1024**3\n",
    "            #     print(f\"  Batch {i}: Memory used: {memory_used:.2f}GB, Cached: {memory_cached:.2f}GB\")\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_d_loss = np.mean(epoch_d_losses) if epoch_d_losses else 0\n",
    "        avg_g_loss = np.mean(epoch_g_losses) if epoch_g_losses else 0\n",
    "        \n",
    "        d_losses.append(avg_d_loss)\n",
    "        g_losses.append(avg_g_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f}\")\n",
    "        \n",
    "        # Clear cache at end of epoch\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return generator, discriminator, d_losses, g_losses, (0, 0)\n",
    "\n",
    "# Memory-efficient sample generation\n",
    "def generate_samples_memory_efficient(generator, num_samples, seq_len, latent_dim, device, data_range):\n",
    "    \"\"\"\n",
    "    Generate samples with very small batches to avoid OOM\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    data_min, data_max = data_range\n",
    "    \n",
    "    generated_batches = []\n",
    "    batch_size = 1  # Generate one sample at a time\n",
    "    \n",
    "    print(f\"Generating {num_samples} samples...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Generated {i}/{num_samples} samples\")\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            z = torch.randn(1, seq_len, latent_dim, device=device)\n",
    "            sample_generated = generator(z)\n",
    "            \n",
    "            # Denormalize from [-1, 1] back to original range\n",
    "            # sample_generated = (sample_generated + 1) / 2 * (data_max - data_min) + data_min\n",
    "            \n",
    "            generated_batches.append(sample_generated.cpu())\n",
    "    \n",
    "    return torch.cat(generated_batches, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dd307",
   "metadata": {},
   "source": [
    "# Multivariate Anomaly Detection GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0267ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Memory-efficient training with very small batches\n",
    "print(\"Starting memory-efficient MAD-GAN training...\")\n",
    "generator, discriminator, d_history, g_history, data_range = train_mad_gan_memory_efficient(\n",
    "    X_train, \n",
    "    device, \n",
    "    epochs=100,              # Reduced epochs due to slower training\n",
    "    batch_size=16,           # Very small batch size\n",
    "    accumulation_steps=8,   # Effective batch size = 16\n",
    "    lr_g=0.005,           \n",
    "    lr_d=0.00005\n",
    ")\n",
    "\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(d_history, label='Discriminator')\n",
    "plt.title('Discriminator Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(g_history, label='Generator')\n",
    "plt.title('Generator Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Clear GPU memory after training\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ee542",
   "metadata": {},
   "source": [
    "# Generate and Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6809752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic samples with memory-efficient approach\n",
    "print(\"Generating synthetic samples...\")\n",
    "num_samples = len(X_train)  # Generate same number of samples as training data\n",
    "seq_len = X_train.shape[1]\n",
    "latent_dim = 50  # Reduced latent dimension\n",
    "\n",
    "generated_data = generate_samples_memory_efficient(\n",
    "    generator, num_samples, seq_len, latent_dim, device, data_range\n",
    ")\n",
    "\n",
    "print(f\"Generated data shape: {generated_data.shape}\")\n",
    "\n",
    "\n",
    "# Combine with real data\n",
    "combine_data_normal = np.concatenate((generated_data, X_train), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21901a15",
   "metadata": {},
   "source": [
    "# Processing: Mel Spec > Resizing > Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01061dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_spectrogram(spectrogram, global_min=None, global_max=None):\n",
    "    \"\"\"\n",
    "    Improved spectrogram processing with consistent normalization\n",
    "    \"\"\"\n",
    "    # Use global min/max for consistent normalization across all spectrograms\n",
    "    if global_min is not None and global_max is not None:\n",
    "        spectrogram = (spectrogram - global_min) / (global_max - global_min + 1e-8)\n",
    "    else:\n",
    "        spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min() + 1e-8)\n",
    "    \n",
    "    # Clip to [0,1] and convert to uint8\n",
    "    spectrogram = np.clip(spectrogram, 0, 1)\n",
    "    spectrogram = np.uint8(spectrogram.cpu().numpy() * 255)\n",
    "    spectrogram = np.stack([spectrogram] * 3, axis=-1)\n",
    "    \n",
    "    image = Image.fromarray(spectrogram)\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "def process_dataset_improved(data, sample_rate=1000):  # More reasonable sample rate\n",
    "    \"\"\"\n",
    "    Improved dataset processing with better mel-spectrogram parameters\n",
    "    \"\"\"\n",
    "    num_samples, seq_len, num_channels = data.shape\n",
    "    features = np.zeros((num_samples, num_channels, 4096))\n",
    "    \n",
    "    # Better mel-spectrogram parameters for sensor data\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=128,\n",
    "        n_fft=512,          # Reasonable FFT size\n",
    "        hop_length=256,     # 50% overlap\n",
    "        win_length=512,\n",
    "        window_fn=torch.hann_window\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load VGG16 model\n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device)\n",
    "    model.classifier = model.classifier[:-3]\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute global min/max for consistent normalization\n",
    "    print(\"Computing global spectrogram statistics...\")\n",
    "    all_mels = []\n",
    "    for i in range(min(100, num_samples)):  # Sample subset for statistics\n",
    "        for j in range(num_channels):\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            all_mels.append(mel.cpu().numpy())\n",
    "    \n",
    "    all_mels = np.concatenate([mel.flatten() for mel in all_mels])\n",
    "    global_min, global_max = np.percentile(all_mels, [1, 99])  # Use percentiles to avoid outliers\n",
    "    \n",
    "    print(f\"Processing {num_samples} samples...\")\n",
    "    for i in range(num_samples):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{num_samples} samples\")\n",
    "            \n",
    "        for j in range(num_channels):\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            \n",
    "            # Use consistent normalization\n",
    "            img = resize_spectrogram(mel, global_min, global_max)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                feat = model(img.unsqueeze(0).to(device))\n",
    "            features[i, j, :] = feat.squeeze().cpu().numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Alternative: Multi-channel processing\n",
    "def process_dataset_multichannel(data, sample_rate=1000):\n",
    "    \"\"\"\n",
    "    Process multiple channels together to capture cross-channel relationships\n",
    "    \"\"\"\n",
    "    num_samples, seq_len, num_channels = data.shape\n",
    "    features = np.zeros((num_samples, 4096))  # Single feature vector per sample\n",
    "    \n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=128,\n",
    "        n_fft=512,\n",
    "        hop_length=256,\n",
    "        win_length=512\n",
    "    ).to(device)\n",
    "    \n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device)\n",
    "    model.classifier = model.classifier[:-3]\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Processing {num_samples} samples with multi-channel approach...\")\n",
    "    for i in range(num_samples):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{num_samples} samples\")\n",
    "        \n",
    "        # Combine multiple channels into RGB image\n",
    "        channel_spectrograms = []\n",
    "        for j in range(min(3, num_channels)):  # Use first 3 channels as RGB\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            \n",
    "            # Normalize each channel spectrogram\n",
    "            mel_norm = (mel - mel.min()) / (mel.max() - mel.min() + 1e-8)\n",
    "            mel_resized = torch.nn.functional.interpolate(\n",
    "                mel_norm.unsqueeze(0).unsqueeze(0), \n",
    "                size=(224, 224), \n",
    "                mode='bilinear'\n",
    "            ).squeeze()\n",
    "            channel_spectrograms.append(mel_resized.cpu().numpy())\n",
    "        \n",
    "        # Stack as RGB image\n",
    "        if len(channel_spectrograms) == 1:\n",
    "            rgb_img = np.stack([channel_spectrograms[0]] * 3, axis=0)\n",
    "        elif len(channel_spectrograms) == 2:\n",
    "            rgb_img = np.stack([channel_spectrograms[0], channel_spectrograms[1], channel_spectrograms[0]], axis=0)\n",
    "        else:\n",
    "            rgb_img = np.stack(channel_spectrograms[:3], axis=0)\n",
    "        \n",
    "        img_tensor = torch.tensor(rgb_img, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            feat = model(img_tensor)\n",
    "        features[i, :] = feat.squeeze().cpu().numpy()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f39ba8",
   "metadata": {},
   "source": [
    "# AE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size=4096):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 64), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 8), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 4), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 16), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, input_size), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "# Train autoencoder\n",
    "def train_autoencoder(features, epochs=20, batch_size=128):\n",
    "    x = torch.tensor(features.reshape(-1, 4096), dtype=torch.float32).to(device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=batch_size, shuffle=True)\n",
    "    model = Autoencoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)  # Add weight decay\n",
    "    criterion = nn.MSELoss()  # Try MSE instead of L1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            # Add noise for denoising autoencoder\n",
    "            noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "            outputs = model(noisy_inputs)\n",
    "            loss = criterion(outputs, inputs)  # Reconstruct clean from noisy\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.6f}\")\n",
    "    return model\n",
    "\n",
    "# Compute reconstruction errors\n",
    "def compute_reconstruction_loss(model, data, add_noise=True):\n",
    "    \"\"\"\n",
    "    Compute reconstruction loss per sample (not per segment)\n",
    "    data: shape (n_samples, n_channels, 4096)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    n_samples, n_channels, n_features = data.shape\n",
    "    sample_errors = []\n",
    "    \n",
    "    # Flatten to (n_samples*n_channels, 4096) for batch processing\n",
    "    x = torch.tensor(data.reshape(-1, n_features), dtype=torch.float32).to(next(model.parameters()).device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=64)\n",
    "    \n",
    "    all_errors = []\n",
    "    criterion = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            \n",
    "            if add_noise:\n",
    "                noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "                outputs = model(noisy_inputs)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            # Per-segment reconstruction error\n",
    "            segment_errors = criterion(outputs, inputs).mean(dim=1)\n",
    "            all_errors.extend(segment_errors.cpu().numpy())\n",
    "    \n",
    "    # Reshape back to (n_samples, n_channels) and aggregate per sample\n",
    "    all_errors = np.array(all_errors).reshape(n_samples, n_channels)\n",
    "    sample_errors = all_errors.mean(axis=1)  # Average across channels per sample\n",
    "    \n",
    "    return sample_errors\n",
    "\n",
    "# 2. Find best threshold based on F1 score\n",
    "def find_best_threshold(errors, labels):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        f1 = f1_score(labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "def find_best_threshold_using_recall(errors, labels):\n",
    "    best_rec = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        rec = recall_score(labels, preds)\n",
    "        if rec > best_rec:\n",
    "            best_rec = rec\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_rec\n",
    "\n",
    "def find_best_threshold_using_precision(errors, labels):\n",
    "    best_prec = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        prec = precision_score(labels, preds)\n",
    "        if prec > best_prec:\n",
    "            best_prec = prec\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_prec\n",
    "\n",
    "def find_best_threshold_using_accuracy(errors, labels):\n",
    "    best_acc = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_acc\n",
    "\n",
    "\n",
    "def evaluate_on_test_with_threshold_search(model, threshold, X_test, y_test):\n",
    "    \"\"\"\n",
    "    X_test: shape (n_samples, 1, 4096) - already has channel dimension added\n",
    "    y_test: shape (n_samples,)\n",
    "    \"\"\"\n",
    "    # X_test already has shape (n_samples, 1, 4096) from your code\n",
    "    # So we can directly compute reconstruction errors\n",
    "    test_errors = compute_reconstruction_loss(model, X_test)\n",
    "    \n",
    "    # Predict using best threshold\n",
    "    test_preds = (test_errors > threshold).astype(int)\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"Evaluation on Test Set:\")\n",
    "    print(\"Accuracy =\", accuracy_score(y_test, test_preds))\n",
    "    print(\"Precision =\", precision_score(y_test, test_preds))\n",
    "    print(\"Recall =\", recall_score(y_test, test_preds))\n",
    "    print(\"F1 Score =\", f1_score(y_test, test_preds))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# THRESHOLD-BASED METHODS\n",
    "# ===============================\n",
    "\n",
    "def find_best_threshold_f1(errors, labels):\n",
    "    \"\"\"Find best threshold based on F1 score\"\"\"\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        f1 = f1_score(labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "def find_best_threshold_accuracy(errors, labels):\n",
    "    \"\"\"Find best threshold based on accuracy\"\"\"\n",
    "    best_acc = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_acc\n",
    "\n",
    "def find_threshold_percentile(errors, percentile=95):\n",
    "    \"\"\"Find threshold based on percentile of normal errors\"\"\"\n",
    "    threshold = np.percentile(errors, percentile)\n",
    "    return threshold\n",
    "\n",
    "def evaluate_threshold_method(errors, labels, threshold):\n",
    "    \"\"\"Evaluate threshold-based method\"\"\"\n",
    "    preds = (errors > threshold).astype(int)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds),\n",
    "        'recall': recall_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds),\n",
    "        'predictions': preds\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# ONE-CLASS SVM METHODS\n",
    "# ===============================\n",
    "\n",
    "def train_one_class_svm(normal_errors, kernel='rbf', nu=0.1, gamma='scale'):\n",
    "    \"\"\"Train One-Class SVM on normal reconstruction errors\"\"\"\n",
    "    normal_errors_2d = normal_errors.reshape(-1, 1)\n",
    "    oc_svm = OneClassSVM(kernel=kernel, nu=nu, gamma=gamma)\n",
    "    oc_svm.fit(normal_errors_2d)\n",
    "    return oc_svm\n",
    "\n",
    "def predict_with_one_class_svm(oc_svm, test_errors):\n",
    "    \"\"\"Predict anomalies using trained One-Class SVM\"\"\"\n",
    "    test_errors_2d = test_errors.reshape(-1, 1)\n",
    "    predictions = oc_svm.predict(test_errors_2d)\n",
    "    binary_predictions = (predictions == -1).astype(int)\n",
    "    return binary_predictions\n",
    "\n",
    "def optimize_one_class_svm_parameters(normal_errors, faulty_errors, param_grid=None):\n",
    "    \"\"\"Optimize One-Class SVM parameters using grid search\"\"\"\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "            'nu': [0.05, 0.1, 0.15, 0.2],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]\n",
    "        }\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_params = None\n",
    "    \n",
    "    print(\"Optimizing One-Class SVM parameters...\")\n",
    "    \n",
    "    val_errors = np.concatenate([normal_errors, faulty_errors])\n",
    "    val_labels = np.concatenate([np.zeros(len(normal_errors)), np.ones(len(faulty_errors))])\n",
    "    \n",
    "    total_combinations = len(param_grid['kernel']) * len(param_grid['nu']) * len(param_grid['gamma'])\n",
    "    current_combination = 0\n",
    "    \n",
    "    for kernel in param_grid['kernel']:\n",
    "        for nu in param_grid['nu']:\n",
    "            for gamma in param_grid['gamma']:\n",
    "                current_combination += 1\n",
    "                \n",
    "                try:\n",
    "                    oc_svm = train_one_class_svm(normal_errors, kernel=kernel, nu=nu, gamma=gamma)\n",
    "                    predictions = predict_with_one_class_svm(oc_svm, val_errors)\n",
    "                    f1 = f1_score(val_labels, predictions)\n",
    "                    \n",
    "                    if f1 > best_f1:\n",
    "                        best_f1 = f1\n",
    "                        best_params = {'kernel': kernel, 'nu': nu, 'gamma': gamma}\n",
    "                    \n",
    "                    if current_combination % 10 == 0:\n",
    "                        print(f\"Progress: {current_combination}/{total_combinations} - Current F1: {f1:.4f}, Best F1: {best_f1:.4f}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error with params kernel={kernel}, nu={nu}, gamma={gamma}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "    \n",
    "    return best_params, best_f1\n",
    "\n",
    "def evaluate_one_class_svm(oc_svm, test_errors, test_labels):\n",
    "    \"\"\"Evaluate One-Class SVM method\"\"\"\n",
    "    preds = predict_with_one_class_svm(oc_svm, test_errors)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(test_labels, preds),\n",
    "        'precision': precision_score(test_labels, preds),\n",
    "        'recall': recall_score(test_labels, preds),\n",
    "        'f1': f1_score(test_labels, preds),\n",
    "        'predictions': preds\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# COMPREHENSIVE EVALUATION\n",
    "# ===============================\n",
    "\n",
    "def comprehensive_anomaly_detection_evaluation_mad_gan(model, normal_train_data, faulty_train_data, \n",
    "                                                      test_data, test_labels, fold_num):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of all anomaly detection methods for MAD-GAN\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} MAD-GAN FOLD {fold_num} EVALUATION {'='*20}\")\n",
    "    \n",
    "    # Compute reconstruction errors\n",
    "    train_errors_normal = compute_reconstruction_loss(model, normal_train_data)\n",
    "    train_errors_faulty = compute_reconstruction_loss(model, faulty_train_data)\n",
    "    test_errors = compute_reconstruction_loss(model, test_data)\n",
    "    \n",
    "    # Combine training errors for validation\n",
    "    val_errors = np.concatenate([train_errors_normal, train_errors_faulty])\n",
    "    val_labels = np.concatenate([np.zeros(len(train_errors_normal)), np.ones(len(train_errors_faulty))])\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # ===============================\n",
    "    # METHOD 1: Threshold based on F1 Score\n",
    "    # ===============================\n",
    "    print(\"\\n1. Threshold Method - F1 Score Optimization\")\n",
    "    threshold_f1, best_f1_val = find_best_threshold_f1(val_errors, val_labels)\n",
    "    print(f\"   Best threshold: {threshold_f1:.6f}, Validation F1: {best_f1_val:.4f}\")\n",
    "    results['threshold_f1'] = evaluate_threshold_method(test_errors, test_labels, threshold_f1)\n",
    "    \n",
    "    # ===============================\n",
    "    # METHOD 2: Threshold based on Accuracy\n",
    "    # ===============================\n",
    "    print(\"\\n2. Threshold Method - Accuracy Optimization\")\n",
    "    threshold_acc, best_acc_val = find_best_threshold_accuracy(val_errors, val_labels)\n",
    "    print(f\"   Best threshold: {threshold_acc:.6f}, Validation Accuracy: {best_acc_val:.4f}\")\n",
    "    results['threshold_accuracy'] = evaluate_threshold_method(test_errors, test_labels, threshold_acc)\n",
    "    \n",
    "    # ===============================\n",
    "    # METHOD 3: Threshold based on Percentile (95th)\n",
    "    # ===============================\n",
    "    print(\"\\n3. Threshold Method - 95th Percentile\")\n",
    "    threshold_95 = find_threshold_percentile(train_errors_normal, percentile=95)\n",
    "    print(f\"   95th percentile threshold: {threshold_95:.6f}\")\n",
    "    results['threshold_95th'] = evaluate_threshold_method(test_errors, test_labels, threshold_95)\n",
    "    \n",
    "    # ===============================\n",
    "    # METHOD 4: One-Class SVM\n",
    "    # ===============================\n",
    "    print(\"\\n4. One-Class SVM Method\")\n",
    "    best_params, best_f1_svm = optimize_one_class_svm_parameters(train_errors_normal, train_errors_faulty)\n",
    "    oc_svm = train_one_class_svm(\n",
    "        train_errors_normal,\n",
    "        kernel=best_params['kernel'],\n",
    "        nu=best_params['nu'],\n",
    "        gamma=best_params['gamma']\n",
    "    )\n",
    "    results['one_class_svm'] = evaluate_one_class_svm(oc_svm, test_errors, test_labels)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"\\n{'='*15} MAD-GAN FOLD {fold_num} RESULTS SUMMARY {'='*15}\")\n",
    "    methods = ['threshold_f1', 'threshold_accuracy', 'threshold_95th', 'one_class_svm']\n",
    "    method_names = ['Threshold (F1)', 'Threshold (Acc)', 'Threshold (95%)', 'One-Class SVM']\n",
    "    \n",
    "    for method, name in zip(methods, method_names):\n",
    "        result = results[method]\n",
    "        print(f\"{name:18s} - Acc: {result['accuracy']:.4f}, Prec: {result['precision']:.4f}, \"\n",
    "              f\"Rec: {result['recall']:.4f}, F1: {result['f1']:.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Error distributions\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(train_errors_normal, bins=30, alpha=0.5, label='Normal', color='blue')\n",
    "    plt.hist(train_errors_faulty, bins=30, alpha=0.5, label='Faulty', color='red')\n",
    "    plt.axvline(threshold_f1, color='green', linestyle='--', label=f'F1 Threshold: {threshold_f1:.4f}')\n",
    "    plt.axvline(threshold_acc, color='orange', linestyle='--', label=f'Acc Threshold: {threshold_acc:.4f}')\n",
    "    plt.axvline(threshold_95, color='purple', linestyle='--', label=f'95% Threshold: {threshold_95:.4f}')\n",
    "    plt.title(f'MAD-GAN Fold {fold_num}: Error Distributions')\n",
    "    plt.xlabel('Reconstruction Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Method comparison - Accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    accuracies = [results[method]['accuracy'] for method in methods]\n",
    "    plt.bar(method_names, accuracies, color=['blue', 'green', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title(f'MAD-GAN Fold {fold_num}: Accuracy Comparison')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Method comparison - F1 Score\n",
    "    plt.subplot(1, 3, 3)\n",
    "    f1_scores = [results[method]['f1'] for method in methods]\n",
    "    plt.bar(method_names, f1_scores, color=['blue', 'green', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title(f'MAD-GAN Fold {fold_num}: F1 Score Comparison')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===============================\n",
    "# MISSING HELPER FUNCTIONS\n",
    "# ===============================\n",
    "\n",
    "def find_best_threshold(errors, labels):\n",
    "    \"\"\"Find best threshold based on F1 score (compatibility function)\"\"\"\n",
    "    return find_best_threshold_f1(errors, labels)\n",
    "\n",
    "def evaluate_on_test_with_threshold_search(model, threshold, test_data, test_labels):\n",
    "    \"\"\"Evaluate model on test set with given threshold\"\"\"\n",
    "    test_errors = compute_reconstruction_loss(model, test_data)\n",
    "    predictions = (test_errors > threshold).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    \n",
    "    print(f\"Test Results with threshold {threshold:.6f}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64ca03",
   "metadata": {},
   "source": [
    "# Comprehensive Anomaly Detection Evaluation\n",
    "\n",
    "This section implements a comprehensive comparison of multiple anomaly detection methods using the MAD-GAN-generated synthetic data:\n",
    "\n",
    "## Methods Compared:\n",
    "1. **Threshold (F1 Score)** - Optimizes threshold for best F1 score\n",
    "2. **Threshold (Accuracy)** - Optimizes threshold for best accuracy  \n",
    "3. **Threshold (95th Percentile)** - Uses 95th percentile of normal errors\n",
    "4. **One-Class SVM** - Uses Support Vector Machine for anomaly detection with hyperparameter optimization\n",
    "\n",
    "## Evaluation Framework:\n",
    "- 5-fold stratified cross-validation\n",
    "- Statistical significance testing\n",
    "- Performance visualization\n",
    "- Method ranking and recommendations\n",
    "\n",
    "## MAD-GAN Specific Features:\n",
    "- Memory-efficient LSTM-based generator and discriminator\n",
    "- Gradient accumulation for stable training\n",
    "- Multivariate time series anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# COMPREHENSIVE CROSS-VALIDATION FRAMEWORK FOR MAD-GAN\n",
    "# ===============================\n",
    "\n",
    "def run_comprehensive_mad_gan_experiment(normal_data, faulty_data, generated_data, \n",
    "                                        normal_labels, faulty_labels, n_splits=5):\n",
    "    \"\"\"\n",
    "    Run comprehensive cross-validation experiment comparing all anomaly detection methods for MAD-GAN\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"COMPREHENSIVE MAD-GAN ANOMALY DETECTION EXPERIMENT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Normal samples: {len(normal_data)}\")\n",
    "    print(f\"Faulty samples: {len(faulty_data)}\")\n",
    "    print(f\"Generated samples: {len(generated_data)}\")\n",
    "    print(f\"Cross-validation folds: {n_splits}\")\n",
    "    \n",
    "    # Combine all data for stratified splitting\n",
    "    all_data = np.concatenate([normal_data, faulty_data], axis=0)\n",
    "    all_labels = np.concatenate([normal_labels, faulty_labels], axis=0)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Storage for results across folds\n",
    "    fold_results = []\n",
    "    \n",
    "    # Process each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(all_data, all_labels)):\n",
    "        print(f\"\\n{'='*20} PROCESSING FOLD {fold+1}/{n_splits} {'='*20}\")\n",
    "        \n",
    "        # Split data by fold indices\n",
    "        train_data_fold = all_data[train_idx]\n",
    "        train_labels_fold = all_labels[train_idx]\n",
    "        test_data_fold = all_data[test_idx]\n",
    "        test_labels_fold = all_labels[test_idx]\n",
    "        \n",
    "        # Separate normal and faulty in training set\n",
    "        normal_train_mask = train_labels_fold == 0\n",
    "        faulty_train_mask = train_labels_fold == 1\n",
    "        \n",
    "        train_normal_fold = train_data_fold[normal_train_mask]\n",
    "        train_faulty_fold = train_data_fold[faulty_train_mask]\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train: {len(train_normal_fold)} normal, {len(train_faulty_fold)} faulty\")\n",
    "        print(f\"Fold {fold+1} - Test: {len(test_data_fold)} total ({np.sum(test_labels_fold==0)} normal, {np.sum(test_labels_fold==1)} faulty)\")\n",
    "        \n",
    "        # Augment normal training data with generated samples\n",
    "        augmented_normal_data = np.concatenate([generated_data, train_normal_fold], axis=0)\n",
    "        print(f\"Fold {fold+1} - Augmented normal data: {len(augmented_normal_data)} samples\")\n",
    "        \n",
    "        # Process data through feature extraction pipeline\n",
    "        print(\"Processing data through feature extraction...\")\n",
    "        augmented_normal_features = process_dataset_multichannel(augmented_normal_data)\n",
    "        train_normal_features = process_dataset_multichannel(train_normal_fold)\n",
    "        train_faulty_features = process_dataset_multichannel(train_faulty_fold)\n",
    "        test_features = process_dataset_multichannel(test_data_fold)\n",
    "        \n",
    "        # Add channel dimension for autoencoder\n",
    "        train_normal_features = train_normal_features[:, np.newaxis, :]\n",
    "        train_faulty_features = train_faulty_features[:, np.newaxis, :]\n",
    "        test_features = test_features[:, np.newaxis, :]\n",
    "        \n",
    "        # Train autoencoder on augmented normal data\n",
    "        print(\"Training autoencoder...\")\n",
    "        model = train_autoencoder(augmented_normal_features, epochs=15, batch_size=32)\n",
    "        \n",
    "        # Run comprehensive evaluation\n",
    "        fold_result = comprehensive_anomaly_detection_evaluation_mad_gan(\n",
    "            model, train_normal_features, train_faulty_features,\n",
    "            test_features, test_labels_fold, fold+1\n",
    "        )\n",
    "        \n",
    "        fold_results.append(fold_result)\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def aggregate_mad_gan_results(fold_results):\n",
    "    \"\"\"\n",
    "    Aggregate results across all folds and compute statistics for MAD-GAN\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MAD-GAN RESULTS AGGREGATION & STATISTICAL ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    methods = ['threshold_f1', 'threshold_accuracy', 'threshold_95th', 'one_class_svm']\n",
    "    method_names = ['Threshold (F1)', 'Threshold (Accuracy)', 'Threshold (95%)', 'One-Class SVM']\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    # Aggregate results\n",
    "    aggregated_results = {}\n",
    "    for method in methods:\n",
    "        aggregated_results[method] = {}\n",
    "        for metric in metrics:\n",
    "            values = [fold_result[method][metric] for fold_result in fold_results]\n",
    "            aggregated_results[method][metric] = {\n",
    "                'mean': np.mean(values),\n",
    "                'std': np.std(values),\n",
    "                'values': values\n",
    "            }\n",
    "    \n",
    "    # Create results DataFrame for better visualization\n",
    "    results_data = []\n",
    "    for method, method_name in zip(methods, method_names):\n",
    "        for metric in metrics:\n",
    "            mean_val = aggregated_results[method][metric]['mean']\n",
    "            std_val = aggregated_results[method][metric]['std']\n",
    "            results_data.append({\n",
    "                'Method': method_name,\n",
    "                'Metric': metric.capitalize(),\n",
    "                'Mean': mean_val,\n",
    "                'Std': std_val,\n",
    "                'Mean±Std': f\"{mean_val:.4f}±{std_val:.4f}\"\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nDETAILED RESULTS SUMMARY:\")\n",
    "    print(\"-\" * 80)\n",
    "    for method, method_name in zip(methods, method_names):\n",
    "        print(f\"\\n{method_name}:\")\n",
    "        for metric in metrics:\n",
    "            mean_val = aggregated_results[method][metric]['mean']\n",
    "            std_val = aggregated_results[method][metric]['std']\n",
    "            print(f\"  {metric.capitalize():10s}: {mean_val:.4f} ± {std_val:.4f}\")\n",
    "    \n",
    "    # Statistical significance testing\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"STATISTICAL SIGNIFICANCE TESTING\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Perform pairwise t-tests for F1 scores\n",
    "    f1_data = {method_name: aggregated_results[method]['f1']['values'] \n",
    "               for method, method_name in zip(methods, method_names)}\n",
    "    \n",
    "    print(\"\\nPairwise t-tests for F1 scores:\")\n",
    "    print(\"(p < 0.05 indicates statistically significant difference)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    method_pairs = [(i, j) for i in range(len(method_names)) for j in range(i+1, len(method_names))]\n",
    "    \n",
    "    for i, j in method_pairs:\n",
    "        method1, method2 = method_names[i], method_names[j]\n",
    "        values1 = f1_data[method1]\n",
    "        values2 = f1_data[method2]\n",
    "        \n",
    "        # Perform paired t-test\n",
    "        statistic, p_value = stats.ttest_rel(values1, values2)\n",
    "        significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "        \n",
    "        print(f\"{method1:18s} vs {method2:18s}: t={statistic:6.3f}, p={p_value:.4f} {significance}\")\n",
    "    \n",
    "    return aggregated_results, results_df\n",
    "\n",
    "def rank_methods_mad_gan(aggregated_results):\n",
    "    \"\"\"\n",
    "    Rank methods based on multiple criteria for MAD-GAN\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"MAD-GAN METHOD RANKING\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    methods = ['threshold_f1', 'threshold_accuracy', 'threshold_95th', 'one_class_svm']\n",
    "    method_names = ['Threshold (F1)', 'Threshold (Accuracy)', 'Threshold (95%)', 'One-Class SVM']\n",
    "    \n",
    "    # Create ranking based on different criteria\n",
    "    rankings = {}\n",
    "    \n",
    "    # Rank by F1 score\n",
    "    f1_scores = [(method_name, aggregated_results[method]['f1']['mean']) \n",
    "                 for method, method_name in zip(methods, method_names)]\n",
    "    f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    rankings['f1'] = f1_scores\n",
    "    \n",
    "    # Rank by accuracy\n",
    "    accuracies = [(method_name, aggregated_results[method]['accuracy']['mean']) \n",
    "                  for method, method_name in zip(methods, method_names)]\n",
    "    accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "    rankings['accuracy'] = accuracies\n",
    "    \n",
    "    # Rank by balanced score (average of precision and recall)\n",
    "    balanced_scores = []\n",
    "    for method, method_name in zip(methods, method_names):\n",
    "        prec = aggregated_results[method]['precision']['mean']\n",
    "        rec = aggregated_results[method]['recall']['mean']\n",
    "        balanced = (prec + rec) / 2\n",
    "        balanced_scores.append((method_name, balanced))\n",
    "    balanced_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    rankings['balanced'] = balanced_scores\n",
    "    \n",
    "    # Print rankings\n",
    "    print(\"\\nRANKING BY F1 SCORE:\")\n",
    "    for i, (method, score) in enumerate(f1_scores, 1):\n",
    "        print(f\"  {i}. {method:22s}: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nRANKING BY ACCURACY:\")\n",
    "    for i, (method, score) in enumerate(accuracies, 1):\n",
    "        print(f\"  {i}. {method:22s}: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nRANKING BY BALANCED SCORE (Precision + Recall)/2:\")\n",
    "    for i, (method, score) in enumerate(balanced_scores, 1):\n",
    "        print(f\"  {i}. {method:22s}: {score:.4f}\")\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "def visualize_mad_gan_results(aggregated_results, fold_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations of the MAD-GAN results\n",
    "    \"\"\"\n",
    "    methods = ['threshold_f1', 'threshold_accuracy', 'threshold_95th', 'one_class_svm']\n",
    "    method_names = ['Threshold (F1)', 'Threshold (Acc)', 'Threshold (95%)', 'One-Class SVM']\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('MAD-GAN: Comprehensive Anomaly Detection Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Mean performance comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    metric_means = []\n",
    "    for metric in metrics:\n",
    "        means = [aggregated_results[method][metric]['mean'] for method in methods]\n",
    "        metric_means.append(means)\n",
    "    \n",
    "    x = np.arange(len(method_names))\n",
    "    width = 0.2\n",
    "    colors = ['blue', 'green', 'orange', 'red']\n",
    "    \n",
    "    for i, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "        ax1.bar(x + i * width, metric_means[i], width, label=metric.capitalize(), color=color, alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Methods')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.set_title('Mean Performance Comparison')\n",
    "    ax1.set_xticks(x + width * 1.5)\n",
    "    ax1.set_xticklabels(method_names, rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: F1 Score with error bars\n",
    "    ax2 = axes[0, 1]\n",
    "    f1_means = [aggregated_results[method]['f1']['mean'] for method in methods]\n",
    "    f1_stds = [aggregated_results[method]['f1']['std'] for method in methods]\n",
    "    \n",
    "    bars = ax2.bar(method_names, f1_means, yerr=f1_stds, capsize=5, color='skyblue', alpha=0.7)\n",
    "    ax2.set_ylabel('F1 Score')\n",
    "    ax2.set_title('F1 Score Comparison (with std dev)')\n",
    "    ax2.set_xticklabels(method_names, rotation=45, ha='right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, mean, std in zip(bars, f1_means, f1_stds):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.01,\n",
    "                f'{mean:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 3: Box plots for F1 scores across folds\n",
    "    ax3 = axes[0, 2]\n",
    "    f1_data = []\n",
    "    for method in methods:\n",
    "        f1_values = [fold_result[method]['f1'] for fold_result in fold_results]\n",
    "        f1_data.append(f1_values)\n",
    "    \n",
    "    bp = ax3.boxplot(f1_data, labels=method_names, patch_artist=True)\n",
    "    colors = ['lightblue', 'lightgreen', 'lightyellow', 'lightcoral']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax3.set_ylabel('F1 Score')\n",
    "    ax3.set_title('F1 Score Distribution Across Folds')\n",
    "    ax3.set_xticklabels(method_names, rotation=45, ha='right')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Precision vs Recall scatter\n",
    "    ax4 = axes[1, 0]\n",
    "    for i, (method, method_name) in enumerate(zip(methods, method_names)):\n",
    "        prec_mean = aggregated_results[method]['precision']['mean']\n",
    "        rec_mean = aggregated_results[method]['recall']['mean']\n",
    "        prec_std = aggregated_results[method]['precision']['std']\n",
    "        rec_std = aggregated_results[method]['recall']['std']\n",
    "        \n",
    "        ax4.errorbar(rec_mean, prec_mean, xerr=rec_std, yerr=prec_std, \n",
    "                    fmt='o', markersize=8, label=method_name, capsize=5)\n",
    "        ax4.text(rec_mean + 0.01, prec_mean + 0.01, method_name, fontsize=9)\n",
    "    \n",
    "    ax4.set_xlabel('Recall')\n",
    "    ax4.set_ylabel('Precision')\n",
    "    ax4.set_title('Precision vs Recall (with std dev)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(0, 1)\n",
    "    ax4.set_ylim(0, 1)\n",
    "    \n",
    "    # Plot 5: Performance consistency (coefficient of variation)\n",
    "    ax5 = axes[1, 1]\n",
    "    cv_data = []\n",
    "    cv_labels = []\n",
    "    for metric in metrics:\n",
    "        cvs = []\n",
    "        for method in methods:\n",
    "            mean_val = aggregated_results[method][metric]['mean']\n",
    "            std_val = aggregated_results[method][metric]['std']\n",
    "            cv = std_val / mean_val if mean_val > 0 else 0\n",
    "            cvs.append(cv)\n",
    "        cv_data.append(cvs)\n",
    "        cv_labels.append(metric.capitalize())\n",
    "    \n",
    "    x = np.arange(len(method_names))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, (cv_values, label, color) in enumerate(zip(cv_data, cv_labels, colors)):\n",
    "        ax5.bar(x + i * width, cv_values, width, label=label, color=color, alpha=0.7)\n",
    "    \n",
    "    ax5.set_xlabel('Methods')\n",
    "    ax5.set_ylabel('Coefficient of Variation')\n",
    "    ax5.set_title('Performance Consistency (Lower is Better)')\n",
    "    ax5.set_xticks(x + width * 1.5)\n",
    "    ax5.set_xticklabels(method_names, rotation=45, ha='right')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Method ranking summary\n",
    "    ax6 = axes[1, 2]\n",
    "    \n",
    "    # Calculate overall rank (average rank across metrics)\n",
    "    overall_ranks = []\n",
    "    for method in methods:\n",
    "        ranks = []\n",
    "        for metric in metrics:\n",
    "            # Get rank for this method in this metric\n",
    "            metric_values = [(aggregated_results[m][metric]['mean'], i) for i, m in enumerate(methods)]\n",
    "            metric_values.sort(reverse=True)\n",
    "            rank = next(i for i, (_, idx) in enumerate(metric_values) if idx == methods.index(method)) + 1\n",
    "            ranks.append(rank)\n",
    "        overall_ranks.append(np.mean(ranks))\n",
    "    \n",
    "    # Sort methods by overall rank\n",
    "    method_rank_pairs = list(zip(method_names, overall_ranks))\n",
    "    method_rank_pairs.sort(key=lambda x: x[1])\n",
    "    \n",
    "    ranked_methods = [pair[0] for pair in method_rank_pairs]\n",
    "    ranked_scores = [pair[1] for pair in method_rank_pairs]\n",
    "    \n",
    "    bars = ax6.barh(range(len(ranked_methods)), ranked_scores, color='gold', alpha=0.7)\n",
    "    ax6.set_yticks(range(len(ranked_methods)))\n",
    "    ax6.set_yticklabels(ranked_methods)\n",
    "    ax6.set_xlabel('Average Rank (Lower is Better)')\n",
    "    ax6.set_title('Overall Method Ranking')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add rank labels\n",
    "    for i, (bar, score) in enumerate(zip(bars, ranked_scores)):\n",
    "        ax6.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2,\n",
    "                f'{score:.2f}', ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def provide_mad_gan_recommendations(aggregated_results, rankings):\n",
    "    \"\"\"\n",
    "    Provide recommendations based on the MAD-GAN analysis\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MAD-GAN ANOMALY DETECTION RECOMMENDATIONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Best overall method\n",
    "    best_f1_method = rankings['f1'][0][0]\n",
    "    best_f1_score = rankings['f1'][0][1]\n",
    "    \n",
    "    best_acc_method = rankings['accuracy'][0][0]\n",
    "    best_acc_score = rankings['accuracy'][0][1]\n",
    "    \n",
    "    print(f\"\\n🏆 BEST METHODS:\")\n",
    "    print(f\"   • Best F1 Score: {best_f1_method} ({best_f1_score:.4f})\")\n",
    "    print(f\"   • Best Accuracy: {best_acc_method} ({best_acc_score:.4f})\")\n",
    "    \n",
    "    # Method characteristics\n",
    "    print(f\"\\n📊 METHOD CHARACTERISTICS:\")\n",
    "    methods = ['threshold_f1', 'threshold_accuracy', 'threshold_95th', 'one_class_svm']\n",
    "    method_names = ['Threshold (F1)', 'Threshold (Accuracy)', 'Threshold (95%)', 'One-Class SVM']\n",
    "    \n",
    "    for method, method_name in zip(methods, method_names):\n",
    "        prec = aggregated_results[method]['precision']['mean']\n",
    "        rec = aggregated_results[method]['recall']['mean']\n",
    "        prec_std = aggregated_results[method]['precision']['std']\n",
    "        rec_std = aggregated_results[method]['recall']['std']\n",
    "        \n",
    "        if prec > rec + 0.05:\n",
    "            characteristic = \"High Precision (fewer false alarms)\"\n",
    "        elif rec > prec + 0.05:\n",
    "            characteristic = \"High Recall (catches more anomalies)\"\n",
    "        else:\n",
    "            characteristic = \"Balanced precision and recall\"\n",
    "            \n",
    "        stability = \"Stable\" if prec_std < 0.1 and rec_std < 0.1 else \"Variable\"\n",
    "        \n",
    "        print(f\"   • {method_name:22s}: {characteristic}, {stability}\")\n",
    "    \n",
    "    # Use case recommendations\n",
    "    print(f\"\\n🎯 USE CASE RECOMMENDATIONS:\")\n",
    "    print(f\"   • For Critical Systems (minimize false negatives): Use method with highest recall\")\n",
    "    print(f\"   • For Cost-Sensitive Systems (minimize false alarms): Use method with highest precision\")\n",
    "    print(f\"   • For Balanced Performance: Use {best_f1_method}\")\n",
    "    print(f\"   • For Simplicity: Use Threshold (95%) - no hyperparameter tuning needed\")\n",
    "    print(f\"   • For Robustness: Use One-Class SVM - adapts to data distribution\")\n",
    "    \n",
    "    # MAD-GAN specific insights\n",
    "    print(f\"\\n🔍 MAD-GAN SPECIFIC INSIGHTS:\")\n",
    "    print(f\"   • LSTM-based architecture captures temporal dependencies in multivariate data\")\n",
    "    print(f\"   • Memory-efficient training enables handling of long sequences\")\n",
    "    print(f\"   • Generated samples enhance autoencoder training for better anomaly detection\")\n",
    "    print(f\"   • Gradient accumulation provides stable training with limited GPU memory\")\n",
    "    print(f\"   • Cross-validation ensures robust evaluation across different data splits\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "\n",
    "# Run the comprehensive experiment\n",
    "print(\"Starting comprehensive MAD-GAN anomaly detection experiment...\")\n",
    "fold_results = run_comprehensive_mad_gan_experiment(\n",
    "    normal_data, faulty_data, generated_data,\n",
    "    normal_label, faulty_label, n_splits=5\n",
    ")\n",
    "\n",
    "# Aggregate and analyze results\n",
    "aggregated_results, results_df = aggregate_mad_gan_results(fold_results)\n",
    "\n",
    "# Rank methods\n",
    "rankings = rank_methods_mad_gan(aggregated_results)\n",
    "\n",
    "# Create visualizations\n",
    "visualize_mad_gan_results(aggregated_results, fold_results)\n",
    "\n",
    "# Provide recommendations\n",
    "provide_mad_gan_recommendations(aggregated_results, rankings)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MAD-GAN COMPREHENSIVE EXPERIMENT COMPLETED!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf28101",
   "metadata": {},
   "source": [
    "# Final Summary & Comparison\n",
    "\n",
    "## MAD-GAN Performance Summary\n",
    "\n",
    "This comprehensive evaluation demonstrates the effectiveness of MAD-GAN for multivariate IoT anomaly detection:\n",
    "\n",
    "### Key Findings:\n",
    "1. **LSTM Architecture**: Successfully captures temporal dependencies in multivariate time series\n",
    "2. **Memory Efficiency**: Gradient accumulation enables training on long sequences with limited GPU memory\n",
    "3. **Data Augmentation**: Generated samples improve autoencoder training robustness\n",
    "4. **Method Comparison**: All four detection methods show competitive performance with statistical validation\n",
    "\n",
    "### MAD-GAN vs Other Approaches:\n",
    "- **Multivariate Focus**: Specifically designed for multivariate anomaly detection\n",
    "- **Temporal Modeling**: LSTM layers capture temporal dependencies better than feed-forward approaches\n",
    "- **Memory Efficiency**: Chunked processing enables handling of very long sequences\n",
    "- **Training Stability**: Gradient accumulation provides stable training with small batches\n",
    "\n",
    "### Method Effectiveness:\n",
    "- **Threshold methods** provide interpretable and fast anomaly detection\n",
    "- **One-Class SVM** offers robust non-parametric detection for complex distributions\n",
    "- **Cross-validation** ensures generalizability across different data splits\n",
    "- **Statistical testing** validates significance of performance differences\n",
    "\n",
    "### MAD-GAN Advantages:\n",
    "1. **Multivariate Anomaly Detection**: Designed specifically for correlated multi-sensor data\n",
    "2. **Temporal Dependencies**: LSTM architecture captures time-based patterns\n",
    "3. **Scalability**: Memory-efficient design handles large-scale sensor networks\n",
    "4. **Robustness**: Statistical validation ensures reliable performance estimates\n",
    "\n",
    "This framework establishes MAD-GAN as a powerful tool for multivariate IoT anomaly detection with comprehensive evaluation and statistical validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcc523",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
