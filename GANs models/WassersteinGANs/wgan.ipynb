{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aca19d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A30\n",
      "(872, 4500, 14) (872,)\n"
     ]
    }
   ],
   "source": [
    "import torch, torchaudio, torchvision.transforms as transforms, matplotlib.pyplot as plt, torch.nn as nn, torch.optim as optim, numpy as np\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import  StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, auc, classification_report, roc_auc_score\n",
    "from torch.autograd import grad\n",
    "\n",
    "\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "cuda1 = torch.device(\"cuda:1\")\n",
    "device = cuda1\n",
    "print(torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"No GPU available\")\n",
    "\n",
    "data = np.load(\"../../hvcm/RFQ.npy\", allow_pickle=True)\n",
    "label = np.load(\"../../hvcm/RFQ_labels.npy\", allow_pickle=True)\n",
    "label = label[:, 1]  # Assuming the second column is the label\n",
    "label = (label == \"Fault\").astype(int)  # Convert to binary labels\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "normal_data = data[label == 0]\n",
    "faulty_data = data[label == 1]\n",
    "\n",
    "normal_label = label[label == 0]\n",
    "faulty_label = label[label == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14127475",
   "metadata": {},
   "source": [
    "# Wasserstein GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71aec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv1d_wgan_raw_stable(normal_data, device, n_epochs=50, batch_size=32, lr_g=0.00005, lr_d=0.0001):\n",
    "    \"\"\"\n",
    "    ULTRA-STABLE WGAN training for raw sensor data\n",
    "    \"\"\"\n",
    "    latent_dim = 100\n",
    "    \n",
    "    # Enhanced data preprocessing\n",
    "    print(f\"Original data range: [{normal_data.min():.4f}, {normal_data.max():.4f}]\")\n",
    "    \n",
    "    # Robust scaling with outlier clipping\n",
    "    data_std = np.std(normal_data)\n",
    "    data_mean = np.mean(normal_data)\n",
    "    scaled_data = (normal_data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    # CRITICAL: Clip extreme outliers\n",
    "    scaled_data = np.clip(scaled_data, -3, 3)\n",
    "    print(f\"Clipped scaled data range: [{scaled_data.min():.4f}, {scaled_data.max():.4f}]\")\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = Conv1DGeneratorStable(latent_dim).to(device)\n",
    "    discriminator = Conv1DDiscriminatorEnhanced().to(device)  # Enhanced discriminator\n",
    "    \n",
    "    # CRITICAL: FIXED weight initialization with proper checks\n",
    "    def weights_init_ultra_stable(m):\n",
    "        if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "            if hasattr(m, 'weight') and m.weight is not None:\n",
    "                nn.init.normal_(m.weight, 0.0, 0.01)  # Smaller weights\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            if hasattr(m, 'weight') and m.weight is not None:\n",
    "                nn.init.normal_(m.weight, 0.0, 0.01)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, (nn.BatchNorm1d, nn.InstanceNorm1d)):\n",
    "            if hasattr(m, 'weight') and m.weight is not None:\n",
    "                nn.init.normal_(m.weight, 1.0, 0.01)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    generator.apply(weights_init_ultra_stable)\n",
    "    discriminator.apply(weights_init_ultra_stable)\n",
    "    \n",
    "    # CRITICAL: Enhanced optimizer settings\n",
    "    optimizer_G = optim.RMSprop(generator.parameters(), lr=lr_g, alpha=0.99, eps=1e-8)\n",
    "    optimizer_D = optim.RMSprop(discriminator.parameters(), lr=lr_d, alpha=0.99, eps=1e-8)\n",
    "    \n",
    "    # CRITICAL: More conservative training parameters\n",
    "    lambda_gp = 0.01  # Very low gradient penalty\n",
    "    n_critic = 5      # More critic updates\n",
    "    clip_value = 0.01 # Very tight gradient clipping\n",
    "    \n",
    "    # Create dataloader with larger batch size\n",
    "    dataset = TensorDataset(torch.tensor(scaled_data, dtype=torch.float32))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    print(\"Starting ULTRA-STABLE WGAN training...\")\n",
    "    print(f\"Learning rates - Generator: {lr_g}, Discriminator: {lr_d}\")\n",
    "    \n",
    "    # Enhanced tracking\n",
    "    d_losses_history = []\n",
    "    g_losses_history = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        unstable_count = 0\n",
    "        \n",
    "        for i, (real_samples,) in enumerate(dataloader):\n",
    "            real_samples = real_samples.to(device)\n",
    "            batch_size_actual = real_samples.size(0)\n",
    "            \n",
    "            # Train Discriminator (multiple times)\n",
    "            for critic_iter in range(n_critic):\n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # Real samples\n",
    "                real_validity = discriminator(real_samples)\n",
    "                \n",
    "                # Fake samples\n",
    "                z = torch.randn(batch_size_actual, latent_dim).to(device)\n",
    "                fake_samples = generator(z).detach()\n",
    "                fake_validity = discriminator(fake_samples)\n",
    "                \n",
    "                # Enhanced gradient penalty with more safety\n",
    "                try:\n",
    "                    gp = compute_gradient_penalty_enhanced(discriminator, real_samples, fake_samples, device)\n",
    "                except Exception as e:\n",
    "                    print(f\"GP failed: {e}\")\n",
    "                    gp = torch.tensor(0.0, device=device)\n",
    "                \n",
    "                # WGAN-GP loss with enhanced stability\n",
    "                wasserstein_distance = torch.mean(real_validity) - torch.mean(fake_validity)\n",
    "                d_loss = -wasserstein_distance + lambda_gp * gp\n",
    "                \n",
    "                # Enhanced safety checks\n",
    "                if (torch.isnan(d_loss) or torch.isinf(d_loss) or \n",
    "                    abs(d_loss.item()) > 50 or\n",
    "                    abs(wasserstein_distance.item()) > 25):\n",
    "                    print(f\"‚ö†Ô∏è  D loss unstable: {d_loss.item():.4f}, WD: {wasserstein_distance.item():.4f}\")\n",
    "                    unstable_count += 1\n",
    "                    continue\n",
    "                \n",
    "                d_loss.backward()\n",
    "                \n",
    "                # CRITICAL: Very tight gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(discriminator.parameters(), clip_value)\n",
    "                \n",
    "                optimizer_D.step()\n",
    "                \n",
    "                if critic_iter == n_critic - 1:\n",
    "                    d_losses.append(d_loss.item())\n",
    "            \n",
    "            # Train Generator (FIXED: Better frequency)\n",
    "            if len(d_losses) > 0 and i % n_critic == 0:  # Train after every n_critic discriminator updates\n",
    "                optimizer_G.zero_grad()\n",
    "                \n",
    "                z = torch.randn(batch_size_actual, latent_dim).to(device)\n",
    "                fake_samples = generator(z)\n",
    "                fake_validity = discriminator(fake_samples)\n",
    "                \n",
    "                # WGAN generator loss\n",
    "                g_loss = -torch.mean(fake_validity)\n",
    "                \n",
    "                # Enhanced safety check\n",
    "                if (torch.isnan(g_loss) or torch.isinf(g_loss) or \n",
    "                    abs(g_loss.item()) > 50):\n",
    "                    print(f\"‚ö†Ô∏è  G loss unstable: {g_loss.item():.4f}\")\n",
    "                    unstable_count += 1\n",
    "                    continue\n",
    "                \n",
    "                g_loss.backward()\n",
    "                \n",
    "                # CRITICAL: Tight gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(generator.parameters(), clip_value)\n",
    "                \n",
    "                optimizer_G.step()\n",
    "                \n",
    "                g_losses.append(g_loss.item())\n",
    "        \n",
    "        # Enhanced progress monitoring\n",
    "        avg_d_loss = np.mean(d_losses) if d_losses else 0\n",
    "        avg_g_loss = np.mean(g_losses) if g_losses else 0\n",
    "        \n",
    "        d_losses_history.append(avg_d_loss)\n",
    "        g_losses_history.append(avg_g_loss)\n",
    "        \n",
    "        # Print progress every epoch\n",
    "        print(f\"Epoch [{epoch}/{n_epochs}]:\")\n",
    "        print(f\"  D Loss: {avg_d_loss:.4f}\")\n",
    "        print(f\"  G Loss: {avg_g_loss:.4f}\")\n",
    "        print(f\"  Unstable Updates: {unstable_count}\")\n",
    "        \n",
    "        # Enhanced stability indicators\n",
    "        if len(d_losses_history) >= 5:\n",
    "            recent_d_std = np.std(d_losses_history[-5:])\n",
    "            recent_g_std = np.std(g_losses_history[-5:])\n",
    "            \n",
    "            if recent_d_std < 0.5 and recent_g_std < 0.5 and abs(avg_d_loss) < 5:\n",
    "                print(\"  ‚úÖ Training highly stable\")\n",
    "            elif recent_d_std < 2.0 and recent_g_std < 2.0 and abs(avg_d_loss) < 15:\n",
    "                print(\"  üîÑ Training moderately stable\")\n",
    "            else:\n",
    "                print(\"  ‚ö†Ô∏è  Training showing instability\")\n",
    "        \n",
    "        # Early stopping for severe instability\n",
    "        if unstable_count > len(dataloader) * 0.3 or abs(avg_d_loss) > 100:\n",
    "            print(\"üí• Training too unstable! Stopping early.\")\n",
    "            break\n",
    "    \n",
    "    return generator, discriminator, d_losses_history, g_losses_history\n",
    "\n",
    "def compute_gradient_penalty_enhanced(discriminator, real_samples, fake_samples, device):\n",
    "    \"\"\"\n",
    "    Enhanced gradient penalty with better stability\n",
    "    \"\"\"\n",
    "    batch_size = real_samples.size(0)\n",
    "    \n",
    "    # Use multiple interpolation points for stability\n",
    "    alpha = torch.rand(batch_size, 1, 1).to(device)\n",
    "    alpha = alpha.expand_as(real_samples)\n",
    "    \n",
    "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "    \n",
    "    # Add small noise for regularization\n",
    "    interpolates = interpolates + 0.001 * torch.randn_like(interpolates)\n",
    "    \n",
    "    try:\n",
    "        d_interpolates = discriminator(interpolates)\n",
    "        \n",
    "        gradients = grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(d_interpolates).to(device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        \n",
    "        gradients = gradients.reshape(batch_size, -1)\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        \n",
    "        # Clamp to prevent explosion\n",
    "        return torch.clamp(gradient_penalty, 0, 10)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced GP computation failed: {e}\")\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "# Enhanced Discriminator with better stability\n",
    "class Conv1DDiscriminatorEnhanced(nn.Module):\n",
    "    def __init__(self, n_features=14, seq_len=4500):\n",
    "        super(Conv1DDiscriminatorEnhanced, self).__init__()\n",
    "        \n",
    "        # More conservative architecture\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Conv1d(n_features, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1),  # Smaller leak\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm1d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.conv_output_size = self._get_conv_output_size(seq_len)\n",
    "        \n",
    "        # Smaller, more stable classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * self.conv_output_size, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def _get_conv_output_size(self, seq_len):\n",
    "        size = seq_len\n",
    "        for _ in range(5):  # 5 conv layers\n",
    "            size = (size - 4 + 2) // 2 + 1\n",
    "        return size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        features = self.conv_blocks(x)\n",
    "        features = features.view(features.shape[0], -1)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "# Stable Generator Architecture\n",
    "class Conv1DGeneratorStable(nn.Module):\n",
    "    def __init__(self, latent_dim=100, n_features=14, seq_len=4500):\n",
    "        super(Conv1DGeneratorStable, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_features = n_features\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.init_size = seq_len // 64\n",
    "        \n",
    "        # More conservative architecture for raw data\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * self.init_size),  # Smaller initial size\n",
    "            nn.BatchNorm1d(128 * self.init_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose1d(8, 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose1d(4, n_features, kernel_size=4, stride=2, padding=1),\n",
    "            # NO final activation for raw data\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size)\n",
    "        out = self.conv_blocks(out)\n",
    "        \n",
    "        if out.shape[2] != self.seq_len:\n",
    "            out = nn.functional.interpolate(out, size=self.seq_len, mode='linear', align_corners=False)\n",
    "        \n",
    "        return out.transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dd307",
   "metadata": {},
   "source": [
    "# WGANS Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0267ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data range: [-3995.8000, 127440.0000]\n",
      "Clipped scaled data range: [-0.3825, 3.0000]\n",
      "Starting ULTRA-STABLE WGAN training...\n",
      "Learning rates - Generator: 5e-05, Discriminator: 0.0001\n",
      "Clipped scaled data range: [-0.3825, 3.0000]\n",
      "Starting ULTRA-STABLE WGAN training...\n",
      "Learning rates - Generator: 5e-05, Discriminator: 0.0001\n",
      "‚ö†Ô∏è  D loss unstable: -25.9008, WD: 26.0008\n",
      "‚ö†Ô∏è  D loss unstable: -26.2938, WD: 26.3938\n",
      "‚ö†Ô∏è  D loss unstable: -26.5310, WD: 26.6310\n",
      "‚ö†Ô∏è  D loss unstable: -26.5116, WD: 26.6116\n",
      "‚ö†Ô∏è  D loss unstable: -27.0375, WD: 27.1375\n",
      "‚ö†Ô∏è  D loss unstable: -26.8980, WD: 26.9980\n",
      "‚ö†Ô∏è  D loss unstable: -26.4304, WD: 26.5267\n",
      "‚ö†Ô∏è  D loss unstable: -26.6254, WD: 26.7254\n",
      "‚ö†Ô∏è  D loss unstable: -27.1500, WD: 27.2500\n",
      "‚ö†Ô∏è  D loss unstable: -26.1044, WD: 26.2044\n",
      "‚ö†Ô∏è  D loss unstable: -26.2884, WD: 26.3884\n",
      "‚ö†Ô∏è  D loss unstable: -26.2295, WD: 26.3295\n",
      "‚ö†Ô∏è  D loss unstable: -26.0050, WD: 26.1050\n",
      "‚ö†Ô∏è  D loss unstable: -25.9008, WD: 26.0008\n",
      "‚ö†Ô∏è  D loss unstable: -26.2938, WD: 26.3938\n",
      "‚ö†Ô∏è  D loss unstable: -26.5310, WD: 26.6310\n",
      "‚ö†Ô∏è  D loss unstable: -26.5116, WD: 26.6116\n",
      "‚ö†Ô∏è  D loss unstable: -27.0375, WD: 27.1375\n",
      "‚ö†Ô∏è  D loss unstable: -26.8980, WD: 26.9980\n",
      "‚ö†Ô∏è  D loss unstable: -26.4304, WD: 26.5267\n",
      "‚ö†Ô∏è  D loss unstable: -26.6254, WD: 26.7254\n",
      "‚ö†Ô∏è  D loss unstable: -27.1500, WD: 27.2500\n",
      "‚ö†Ô∏è  D loss unstable: -26.1044, WD: 26.2044\n",
      "‚ö†Ô∏è  D loss unstable: -26.2884, WD: 26.3884\n",
      "‚ö†Ô∏è  D loss unstable: -26.2295, WD: 26.3295\n",
      "‚ö†Ô∏è  D loss unstable: -26.0050, WD: 26.1050\n",
      "‚ö†Ô∏è  D loss unstable: -26.1487, WD: 26.1785\n",
      "‚ö†Ô∏è  D loss unstable: -26.3852, WD: 26.4852\n",
      "‚ö†Ô∏è  D loss unstable: -27.1557, WD: 27.2557\n",
      "‚ö†Ô∏è  D loss unstable: -26.1418, WD: 26.2418\n",
      "‚ö†Ô∏è  D loss unstable: -27.7472, WD: 27.8472\n",
      "‚ö†Ô∏è  D loss unstable: -26.0832, WD: 26.1832\n",
      "‚ö†Ô∏è  D loss unstable: -26.5793, WD: 26.6793\n",
      "‚ö†Ô∏è  D loss unstable: -27.5966, WD: 27.6966\n",
      "‚ö†Ô∏è  D loss unstable: -27.3514, WD: 27.4514\n",
      "‚ö†Ô∏è  D loss unstable: -26.6715, WD: 26.7715\n",
      "‚ö†Ô∏è  D loss unstable: -26.2740, WD: 26.3740\n",
      "‚ö†Ô∏è  D loss unstable: -25.7335, WD: 25.8335\n",
      "Epoch [0/25]:\n",
      "  D Loss: -9.4743\n",
      "  G Loss: 5.8813\n",
      "  Unstable Updates: 25\n",
      "üí• Training too unstable! Stopping early.\n",
      "‚ö†Ô∏è  D loss unstable: -26.1487, WD: 26.1785\n",
      "‚ö†Ô∏è  D loss unstable: -26.3852, WD: 26.4852\n",
      "‚ö†Ô∏è  D loss unstable: -27.1557, WD: 27.2557\n",
      "‚ö†Ô∏è  D loss unstable: -26.1418, WD: 26.2418\n",
      "‚ö†Ô∏è  D loss unstable: -27.7472, WD: 27.8472\n",
      "‚ö†Ô∏è  D loss unstable: -26.0832, WD: 26.1832\n",
      "‚ö†Ô∏è  D loss unstable: -26.5793, WD: 26.6793\n",
      "‚ö†Ô∏è  D loss unstable: -27.5966, WD: 27.6966\n",
      "‚ö†Ô∏è  D loss unstable: -27.3514, WD: 27.4514\n",
      "‚ö†Ô∏è  D loss unstable: -26.6715, WD: 26.7715\n",
      "‚ö†Ô∏è  D loss unstable: -26.2740, WD: 26.3740\n",
      "‚ö†Ô∏è  D loss unstable: -25.7335, WD: 25.8335\n",
      "Epoch [0/25]:\n",
      "  D Loss: -9.4743\n",
      "  G Loss: 5.8813\n",
      "  Unstable Updates: 25\n",
      "üí• Training too unstable! Stopping early.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the stable version\n",
    "trained_generator, trained_discriminator, d_history, g_history = train_conv1d_wgan_raw_stable(\n",
    "    normal_data, \n",
    "    device, \n",
    "    n_epochs=25,      # Start with fewer epochs\n",
    "    batch_size=64,    # Larger batch for stability\n",
    "    lr_g=0.00005,     # Keep these rates\n",
    "    lr_d=0.0001\n",
    ")\n",
    "# Monitor training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(d_history, label='Discriminator')\n",
    "plt.title('Discriminator Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(g_history, label='Generator')\n",
    "plt.title('Generator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ee542",
   "metadata": {},
   "source": [
    "# Generate and Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6809752",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim).to(device)\n",
    "num_samples = len(data[label == 0])  # Number of synthetic samples to generate\n",
    "batch_size = 64  # Generate in batches to avoid memory issues\n",
    "\n",
    "generated_list = []\n",
    "for i in range(0, num_samples, batch_size):\n",
    "\tcurrent_batch = min(batch_size, num_samples - i)\n",
    "\tz = torch.randn(current_batch, latent_dim).to(device)\n",
    "\twith torch.no_grad():\n",
    "\t\tbatch_samples = generator(z).cpu().numpy()\n",
    "\t# batch_samples shape: (current_batch, 14, 10, 15, 30)\n",
    "\tbatch_samples = batch_samples.reshape(current_batch, 14, -1).transpose(0, 2, 1)  # (current_batch, 4500, 14)\n",
    "\tgenerated_list.append(batch_samples)\n",
    "\n",
    "generated_samples = np.concatenate(generated_list, axis=0)  # (num_samples, 4500, 14)\n",
    "\n",
    "combine_data_normal = np.concatenate((generated_samples, normal_data), axis=0)  # Combine real and generated data\n",
    "combine_labels_normal = np.concatenate((np.zeros(num_samples), normal_label), axis=0)  # Labels: 0 for generated, 1 for real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21901a15",
   "metadata": {},
   "source": [
    "# Processing: Mel Spec > Resizing > Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01061dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and convert to 3-channel image\n",
    "def resize_spectrogram(spectrogram):\n",
    "    spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min() + 1e-6)\n",
    "    spectrogram = np.uint8(spectrogram.cpu().numpy() * 255)\n",
    "    spectrogram = np.stack([spectrogram] * 3, axis=-1)\n",
    "    image = Image.fromarray(spectrogram)\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "# Process dataset\n",
    "def process_dataset(data):\n",
    "    num_samples, _, num_channels = data.shape\n",
    "    features = np.zeros((num_samples, num_channels, 4096))\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=2500000, n_mels=128).to(device)\n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device)\n",
    "    model.classifier = model.classifier[:-3]\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_channels):\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            img = resize_spectrogram(mel)\n",
    "            with torch.no_grad():\n",
    "                feat = model(img.unsqueeze(0).to(device))\n",
    "            features[i, j, :] = feat.squeeze().cpu().numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f39ba8",
   "metadata": {},
   "source": [
    "# AE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size=4096):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 64), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 8), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 4), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_size), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "# Train autoencoder\n",
    "def train_autoencoder(features, epochs=20, batch_size=128):\n",
    "    x = torch.tensor(features.reshape(-1, 4096), dtype=torch.float32).to(device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=batch_size, shuffle=True)\n",
    "    model = Autoencoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.6f}\")\n",
    "    return model\n",
    "\n",
    "# Compute reconstruction errors\n",
    "def compute_reconstruction_loss(model, data):\n",
    "    model.eval()\n",
    "    x = torch.tensor(data.reshape(-1, 4096), dtype=torch.float32).to(next(model.parameters()).device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=64)\n",
    "    loss = []\n",
    "    criterion = torch.nn.MSELoss(reduction='none')\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            outputs = model(inputs)\n",
    "            batch_errors = criterion(outputs, inputs).mean(dim=1)\n",
    "            loss.extend(batch_errors.cpu().numpy())\n",
    "    return np.array(loss)\n",
    "\n",
    "# 2. Find best threshold based on F1 score\n",
    "def find_best_threshold(errors, labels):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        f1 = f1_score(labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "def evaluate_on_test_with_threshold_search(model, X_test, y_test):\n",
    "    # Step 1: Flatten the test data\n",
    "    n_samples, n_segments, n_features = X_test.shape\n",
    "    X_test_flat = X_test.reshape(-1, n_features)\n",
    "\n",
    "    # Step 2: Compute reconstruction errors per segment\n",
    "    segment_errors = compute_reconstruction_loss(model, X_test_flat)\n",
    "\n",
    "    # Step 3: Aggregate errors per sample (mean over segments)\n",
    "    sample_errors = segment_errors.reshape(n_samples, n_segments).mean(axis=1)\n",
    "\n",
    "    # Step 4: Find best threshold based on F1 score\n",
    "    best_threshold = 0\n",
    "    best_f1 = 0\n",
    "    for threshold in np.linspace(sample_errors.min(), sample_errors.max(), 100):\n",
    "        preds = (sample_errors > threshold).astype(int)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    # Step 5: Predict using best threshold\n",
    "    test_preds = (sample_errors > best_threshold).astype(int)\n",
    "\n",
    "    # Step 6: Evaluate\n",
    "    print(f\"Best Threshold = {best_threshold:.6f}, Best F1 Score = {best_f1:.4f}\")\n",
    "    print(\"Evaluation on Test Set:\")\n",
    "    print(\"Accuracy =\", accuracy_score(y_test, test_preds))\n",
    "    print(\"Precision =\", precision_score(y_test, test_preds))\n",
    "    print(\"Recall =\", recall_score(y_test, test_preds))\n",
    "    print(\"F1 Score =\", f1_score(y_test, test_preds))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81797ba0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = np.concatenate((combine_data_normal, data[label == 1]), axis=0)  # Combine real and generated data\n",
    "combine_label = np.concatenate((np.zeros(len(combine_labels_normal)), label[label == 1]), axis=0)  # Labels: 0 for real, 0 for generated\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scaled_data = StandardScaler().fit_transform(combine_data.reshape(-1, combine_data.shape[-1])).reshape(combine_data.shape)\n",
    "features = process_dataset(scaled_data)\n",
    "print(\"Features shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64ca03",
   "metadata": {},
   "source": [
    "# Cross Validation with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(features, combine_label)):\n",
    "    \n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Get full fold data\n",
    "    fold_data, fold_labels = features[train_idx], combine_label[train_idx]\n",
    "    val_data, val_labels = features[val_idx], combine_label[val_idx]\n",
    "   \n",
    "    # Split into training and validation folds\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(fold_data, fold_labels, test_size=0.2, shuffle=True, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(val_data, val_labels, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Train autoencoder on the training fold\n",
    "    model = train_autoencoder(X_train[y_train == 0], epochs=15, batch_size=32)\n",
    "\n",
    "    # Evaluate on validation fold\n",
    "    val_errors_normal = compute_reconstruction_loss(model, X_val[y_val == 0])\n",
    "    val_errors_abnormal = compute_reconstruction_loss(model, X_val[y_val == 1])\n",
    "    val_errors = np.concatenate([val_errors_normal, val_errors_abnormal])\n",
    "    y_val_combined = np.concatenate([np.zeros(len(val_errors_normal)), np.ones(len(val_errors_abnormal))])\n",
    "    \n",
    "    threshold, best_f1 = find_best_threshold(val_errors, y_val_combined)\n",
    "    print(f\"Best threshold: {threshold}, Best F1 Score: {best_f1}\")\n",
    "\n",
    "    # Plot histogram of reconstruction errors on both normal and abnormal samples\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(val_errors_normal, bins=50, alpha=0.5, label='Normal Samples', color='blue')\n",
    "    plt.hist(val_errors_abnormal, bins=50, alpha=0.5, label='Abnormal Samples', color='red')\n",
    "    plt.axvline(threshold, color='black', linestyle='--', label='Threshold')\n",
    "    plt.title('Reconstruction Errors on Validation Set')\n",
    "    plt.xlabel('Reconstruction Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    val_errors_test = compute_reconstruction_loss(model, X_test)\n",
    "    \n",
    "\n",
    "    # Evaluate on test set\n",
    "    evaluate_on_test_with_threshold_search(model, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25980ecb",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "\n",
    "Accuracy = 0.9166666666666666\n",
    "\n",
    "\n",
    "Precision = 0.7142857142857143\n",
    "\n",
    "Recall = 0.3125\n",
    "\n",
    "F1 Score = 0.43478260869565216\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    " [[138   2]\n",
    "\n",
    " [ 11   5]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ffa6f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
