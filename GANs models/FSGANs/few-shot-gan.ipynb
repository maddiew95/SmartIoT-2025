{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio, torchvision.transforms as transforms, matplotlib.pyplot as plt, torch.nn as nn, torch.optim as optim, numpy as np\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, auc, classification_report, roc_auc_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from torch.autograd import grad\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "cuda1 = torch.device(\"cuda:1\")\n",
    "device = cuda1\n",
    "print(torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"No GPU available\")\n",
    "\n",
    "data = np.load(\"../../hvcm/RFQ.npy\", allow_pickle=True)\n",
    "label = np.load(\"../../hvcm/RFQ_labels.npy\", allow_pickle=True)\n",
    "label = label[:, 1]  # Assuming the second column is the label\n",
    "label = (label == \"Fault\").astype(int)  # Convert to binary labels\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data.reshape(-1, data.shape[-1])).reshape(data.shape)\n",
    "\n",
    "normal_data = data[label == 0]\n",
    "faulty_data = data[label == 1]\n",
    "\n",
    "normal_label = label[label == 0]\n",
    "faulty_label = label[label == 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normal_data, normal_label, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14127475",
   "metadata": {},
   "source": [
    "# Few-Shot GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Attention mechanism for Few-Shot learning\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, attention_dim=64):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, attention_dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(attention_dim, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attention_weights = self.attention(x)\n",
    "        return x * attention_weights\n",
    "\n",
    "# Enhanced Few-Shot Generator with Attention and Residual Connections\n",
    "class EnhancedFewShotGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, channels=14, seq_len=4500):\n",
    "        super(EnhancedFewShotGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.channels = channels\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        # Start with a smaller sequence length and upsample\n",
    "        self.init_seq_len = seq_len // 32  # More aggressive downsampling\n",
    "        \n",
    "        # Enhanced initial projection with batch normalization\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256 * self.init_seq_len),\n",
    "            nn.BatchNorm1d(256 * self.init_seq_len),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Progressive upsampling with attention and residual connections\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            # Block 1: 256 -> 128 channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                AttentionBlock(128)\n",
    "            ),\n",
    "            # Block 2: 128 -> 64 channels  \n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                AttentionBlock(64)\n",
    "            ),\n",
    "            # Block 3: 64 -> 32 channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ),\n",
    "            # Block 4: 32 -> 16 channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ),\n",
    "            # Final block: 16 -> channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(16, channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 256, self.init_seq_len)\n",
    "        \n",
    "        # Progressive upsampling with skip connections\n",
    "        for i, block in enumerate(self.conv_blocks):\n",
    "            out = block(out)\n",
    "        \n",
    "        # Ensure exact sequence length through interpolation if needed\n",
    "        if out.size(2) != self.seq_len:\n",
    "            out = nn.functional.interpolate(out, size=self.seq_len, mode='linear', align_corners=False)\n",
    "        \n",
    "        return out  # Shape: (batch, 14, 4500)\n",
    "\n",
    "# Enhanced Few-Shot Discriminator with Multi-Scale Features\n",
    "class EnhancedFewShotDiscriminator(nn.Module):\n",
    "    def __init__(self, channels=14, seq_len=4500):\n",
    "        super(EnhancedFewShotDiscriminator, self).__init__()\n",
    "        \n",
    "        # Multi-scale feature extraction\n",
    "        self.scale1_conv = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(channels, 32, kernel_size=3, stride=1, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.utils.spectral_norm(nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.scale2_conv = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(channels, 32, kernel_size=7, stride=1, padding=3)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.utils.spectral_norm(nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Feature fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        # Further processing\n",
    "        self.model = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.utils.spectral_norm(nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.utils.spectral_norm(nn.Linear(512, 256)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.utils.spectral_norm(nn.Linear(256, 1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Multi-scale feature extraction\n",
    "        scale1_features = self.scale1_conv(x)\n",
    "        scale2_features = self.scale2_conv(x)\n",
    "        \n",
    "        # Concatenate multi-scale features\n",
    "        multi_scale_features = torch.cat([scale1_features, scale2_features], dim=1)\n",
    "        \n",
    "        # Fusion and classification\n",
    "        fused_features = self.fusion(multi_scale_features)\n",
    "        output = self.model(fused_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class FewShot1DDataset(Dataset):\n",
    "    def __init__(self, data, labels=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape [n_samples, 4500, 14]\n",
    "            labels: numpy array of shape [n_samples] (optional)\n",
    "        \"\"\"\n",
    "        # Transpose to (n_samples, 14, 4500) for Conv1d\n",
    "        self.data = torch.tensor(data.transpose(0, 2, 1), dtype=torch.float32)\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]  # Shape: (14, 4500)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return sample, label\n",
    "        return sample, 0\n",
    "\n",
    "# Enhanced training function with few-shot learning capabilities\n",
    "def train_enhanced_few_shot_gan(normal_data, device, epochs=100, batch_size=32, lr_g=1e-4, lr_d=2e-4):\n",
    "    \"\"\"\n",
    "    Enhanced Few-Shot GAN training with improved stability and attention mechanisms\n",
    "    \"\"\"\n",
    "    print(f\"Training Enhanced Few-Shot GAN on data shape: {normal_data.shape}\")\n",
    "    \n",
    "    # Data loading\n",
    "    dataset = FewShot1DDataset(normal_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Initialize enhanced models\n",
    "    latent_dim = 100\n",
    "    num_channels = normal_data.shape[-1]\n",
    "    seq_length = normal_data.shape[1]\n",
    "    \n",
    "    generator = EnhancedFewShotGenerator(latent_dim=latent_dim, channels=num_channels, seq_len=seq_length).to(device)\n",
    "    discriminator = EnhancedFewShotDiscriminator(channels=num_channels, seq_len=seq_length).to(device)\n",
    "\n",
    "    # Xavier/He initialization for better stability\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d, nn.Linear)):\n",
    "            nn.init.xavier_normal_(m.weight, gain=0.02)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    generator.apply(init_weights)\n",
    "    discriminator.apply(init_weights)\n",
    "\n",
    "    # Optimizers with different learning rates for stability\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "\n",
    "    # Learning rate schedulers\n",
    "    scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, patience=20, factor=0.8)\n",
    "    scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, patience=20, factor=0.8)\n",
    "\n",
    "    # Enhanced loss function with label smoothing\n",
    "    def adversarial_loss_smooth(pred, target_is_real, smoothing=0.1):\n",
    "        if target_is_real:\n",
    "            target = torch.ones_like(pred) * (1.0 - smoothing) + smoothing * torch.rand_like(pred)\n",
    "        else:\n",
    "            target = torch.zeros_like(pred) + smoothing * torch.rand_like(pred)\n",
    "        return nn.BCELoss()(pred, target)\n",
    "\n",
    "    # Training history\n",
    "    g_losses, d_losses = [], []\n",
    "    \n",
    "    print(\"Starting Enhanced Few-Shot GAN training...\")\n",
    "    print(f\"Generator LR: {lr_g}, Discriminator LR: {lr_d}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_g_loss, epoch_d_loss = 0, 0\n",
    "        \n",
    "        for i, (real_samples, _) in enumerate(dataloader):\n",
    "            real_samples = real_samples.to(device)  # Shape: (batch, 14, 4500)\n",
    "            batch_size_actual = real_samples.size(0)\n",
    "            \n",
    "            # Add noise to real samples for robustness\n",
    "            noisy_real = real_samples + 0.05 * torch.randn_like(real_samples)\n",
    "            \n",
    "            # ========================\n",
    "            # Train Discriminator\n",
    "            # ========================\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real samples\n",
    "            real_pred = discriminator(noisy_real)\n",
    "            d_real_loss = adversarial_loss_smooth(real_pred, True)\n",
    "            \n",
    "            # Fake samples\n",
    "            z = torch.randn(batch_size_actual, latent_dim, device=device)\n",
    "            fake_samples = generator(z).detach()\n",
    "            fake_pred = discriminator(fake_samples)\n",
    "            d_fake_loss = adversarial_loss_smooth(fake_pred, False)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 0.5)\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # ========================\n",
    "            # Train Generator\n",
    "            # ========================\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake samples\n",
    "            z = torch.randn(batch_size_actual, latent_dim, device=device)\n",
    "            fake_samples = generator(z)\n",
    "            fake_pred = discriminator(fake_samples)\n",
    "            \n",
    "            # Generator loss (want discriminator to classify fake as real)\n",
    "            g_loss = adversarial_loss_smooth(fake_pred, True)\n",
    "            g_loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(generator.parameters(), 0.5)\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                      f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "\n",
    "        # Store average losses per epoch\n",
    "        avg_g_loss = epoch_g_loss / len(dataloader)\n",
    "        avg_d_loss = epoch_d_loss / len(dataloader)\n",
    "        g_losses.append(avg_g_loss)\n",
    "        d_losses.append(avg_d_loss)\n",
    "\n",
    "        # Update learning rates\n",
    "        scheduler_G.step(avg_g_loss)\n",
    "        scheduler_D.step(avg_d_loss)\n",
    "\n",
    "        # Enhanced stability monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            monitor_gan_stability(g_losses, d_losses, window=10)\n",
    "    \n",
    "    print(\"Enhanced Few-Shot GAN training completed!\")\n",
    "    return generator, discriminator, g_losses, d_losses\n",
    "\n",
    "def generate_samples(generator, num_samples, latent_dim=100):\n",
    "    \"\"\"\n",
    "    Generate samples using the trained generator\n",
    "    Returns data in shape (num_samples, 4500, 14)\n",
    "    \"\"\"\n",
    "    device = next(generator.parameters()).device\n",
    "    generator.eval()\n",
    "    \n",
    "    batch_size = 16\n",
    "    all_samples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            current_batch_size = end - start\n",
    "            \n",
    "            z = torch.randn(current_batch_size, latent_dim, device=device)\n",
    "            batch_samples = generator(z)  # Shape: (batch, 14, 4500)\n",
    "            all_samples.append(batch_samples.cpu())\n",
    "    \n",
    "    generated_data = torch.cat(all_samples, dim=0).numpy()\n",
    "    \n",
    "    # Transpose back to (n_samples, 4500, 14)\n",
    "    generated_data = generated_data.transpose(0, 2, 1)\n",
    "    \n",
    "    return generated_data\n",
    "\n",
    "# Enhanced monitoring with more detailed analysis\n",
    "def monitor_gan_stability(g_losses, d_losses, window=10):\n",
    "    \"\"\"\n",
    "    Enhanced GAN training stability monitoring\n",
    "    \"\"\"\n",
    "    if len(g_losses) < window:\n",
    "        return\n",
    "    \n",
    "    # Recent losses\n",
    "    recent_g = np.mean(g_losses[-window:])\n",
    "    recent_d = np.mean(d_losses[-window:])\n",
    "    \n",
    "    # Loss ratio (should be roughly balanced)\n",
    "    ratio = recent_g / (recent_d + 1e-8)\n",
    "    \n",
    "    # Loss variance (should be stable, not oscillating wildly)\n",
    "    g_var = np.var(g_losses[-window:])\n",
    "    d_var = np.var(d_losses[-window:])\n",
    "    \n",
    "    # Loss trend analysis\n",
    "    if len(g_losses) >= window * 2:\n",
    "        g_trend = np.mean(g_losses[-window:]) - np.mean(g_losses[-window*2:-window])\n",
    "        d_trend = np.mean(d_losses[-window:]) - np.mean(d_losses[-window*2:-window])\n",
    "    else:\n",
    "        g_trend = d_trend = 0\n",
    "    \n",
    "    print(f\"G/D Ratio: {ratio:.3f} | G_var: {g_var:.4f} | D_var: {d_var:.4f}\")\n",
    "    print(f\"G_trend: {g_trend:+.4f} | D_trend: {d_trend:+.4f}\")\n",
    "    \n",
    "    # Enhanced stability warnings\n",
    "    if ratio > 5:\n",
    "        print(\"⚠️  Generator significantly overpowering Discriminator\")\n",
    "        print(\"   💡 Consider: Lower G learning rate or train D more frequently\")\n",
    "    elif ratio < 0.2:\n",
    "        print(\"⚠️  Discriminator significantly overpowering Generator\")\n",
    "        print(\"   💡 Consider: Lower D learning rate or add noise to real data\")\n",
    "    elif g_var > 1.0 or d_var > 1.0:\n",
    "        print(\"⚠️  High variance - unstable training detected\")\n",
    "        print(\"   💡 Consider: Lower learning rates or gradient clipping\")\n",
    "    elif abs(g_trend) > 0.5 or abs(d_trend) > 0.5:\n",
    "        print(\"⚠️  Significant loss trends detected\")\n",
    "        print(\"   💡 Consider: Learning rate scheduling or early stopping\")\n",
    "    else:\n",
    "        print(\"✅ Training appears stable and balanced\")\n",
    "\n",
    "# Enhanced visualization\n",
    "def plot_enhanced_training_curves(g_losses, d_losses):\n",
    "    \"\"\"\n",
    "    Plot enhanced training curves with additional analysis\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(g_losses, label='Generator Loss', alpha=0.7)\n",
    "    axes[0, 0].plot(d_losses, label='Discriminator Loss', alpha=0.7)\n",
    "    axes[0, 0].set_title('Training Losses')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss ratio\n",
    "    ratios = [g/(d+1e-8) for g, d in zip(g_losses, d_losses)]\n",
    "    axes[0, 1].plot(ratios, color='green', alpha=0.7)\n",
    "    axes[0, 1].axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Ideal Ratio')\n",
    "    axes[0, 1].set_title('Generator/Discriminator Loss Ratio')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('G_loss / D_loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Moving averages\n",
    "    window = 10\n",
    "    if len(g_losses) >= window:\n",
    "        g_ma = pd.Series(g_losses).rolling(window=window).mean()\n",
    "        d_ma = pd.Series(d_losses).rolling(window=window).mean()\n",
    "        \n",
    "        axes[1, 0].plot(g_ma, label=f'Generator MA({window})', alpha=0.7)\n",
    "        axes[1, 0].plot(d_ma, label=f'Discriminator MA({window})', alpha=0.7)\n",
    "        axes[1, 0].set_title('Moving Average Losses')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Loss')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss variance\n",
    "    if len(g_losses) >= window:\n",
    "        g_var = pd.Series(g_losses).rolling(window=window).var()\n",
    "        d_var = pd.Series(d_losses).rolling(window=window).var()\n",
    "        \n",
    "        axes[1, 1].plot(g_var, label=f'Generator Var({window})', alpha=0.7)\n",
    "        axes[1, 1].plot(d_var, label=f'Discriminator Var({window})', alpha=0.7)\n",
    "        axes[1, 1].set_title('Loss Variance (Stability Indicator)')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Variance')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dd307",
   "metadata": {},
   "source": [
    "# Few-Shot GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0267ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=100\n",
    "epochs=100\n",
    "batch_size=32\n",
    "save_interval=5\n",
    "\n",
    "# Data loading\n",
    "dataset = FewShot1DDataset(X_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Initialize models\n",
    "num_channels = 14\n",
    "seq_length = 4500\n",
    "generator = Generator(latent_dim=latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.00005, )\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0015)\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "g_losses, d_losses = [], []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_g_loss, epoch_d_loss = 0, 0\n",
    "    for i, (real_samples, _) in enumerate(dataloader):\n",
    "        real_samples = real_samples.to(device)  # Shape: (batch, 14, 4500)\n",
    "        \n",
    "        # Ground truths\n",
    "        valid = torch.ones(real_samples.size(0), 1, device=device) * 0.9\n",
    "        fake = torch.zeros(real_samples.size(0), 1, device=device) * 0.1\n",
    "        noisy_real = real_samples + 0.05 * torch.randn_like(real_samples)\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(real_samples.size(0), latent_dim, device=device)\n",
    "        gen_samples = generator(z)  # Shape: (batch, 14, 4500)\n",
    "        g_loss = adversarial_loss(discriminator(gen_samples), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_samples), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_samples.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                  f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "            epoch_g_loss += g_loss.item()\n",
    "        epoch_d_loss += d_loss.item()\n",
    "        \n",
    "  \n",
    "    # Store average losses per epoch\n",
    "    g_losses.append(epoch_g_loss / len(dataloader))\n",
    "    d_losses.append(epoch_d_loss / len(dataloader))\n",
    "    \n",
    "\n",
    "    monitor_gan_stability(g_losses, d_losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ee542",
   "metadata": {},
   "source": [
    "# Generate and Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6809752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "num_samples = len(X_train)  # Number of samples to generate\n",
    "generated_data = generate_samples(generator, num_samples)\n",
    "\n",
    "# Combine with real data\n",
    "combine_data_normal = np.concatenate((generated_data, normal_data), axis=0)\n",
    "combine_labels_normal = np.concatenate((np.zeros(num_samples), normal_label), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21901a15",
   "metadata": {},
   "source": [
    "# Processing: Mel Spec > Resizing > Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01061dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_spectrogram(spectrogram, global_min=None, global_max=None):\n",
    "    \"\"\"\n",
    "    Improved spectrogram processing with consistent normalization\n",
    "    \"\"\"\n",
    "    # Use global min/max for consistent normalization across all spectrograms\n",
    "    if global_min is not None and global_max is not None:\n",
    "        spectrogram = (spectrogram - global_min) / (global_max - global_min + 1e-8)\n",
    "    else:\n",
    "        spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min() + 1e-8)\n",
    "    \n",
    "    # Clip to [0,1] and convert to uint8\n",
    "    spectrogram = np.clip(spectrogram, 0, 1)\n",
    "    spectrogram = np.uint8(spectrogram.cpu().numpy() * 255)\n",
    "    spectrogram = np.stack([spectrogram] * 3, axis=-1)\n",
    "    \n",
    "    image = Image.fromarray(spectrogram)\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "def process_dataset_improved(data, sample_rate=1000):  # More reasonable sample rate\n",
    "    \"\"\"\n",
    "    Improved dataset processing with better mel-spectrogram parameters\n",
    "    \"\"\"\n",
    "    num_samples, seq_len, num_channels = data.shape\n",
    "    features = np.zeros((num_samples, num_channels, 4096))\n",
    "    \n",
    "    # Better mel-spectrogram parameters for sensor data\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=128,\n",
    "        n_fft=512,          # Reasonable FFT size\n",
    "        hop_length=256,     # 50% overlap\n",
    "        win_length=512,\n",
    "        window_fn=torch.hann_window\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load VGG16 model\n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device)\n",
    "    model.classifier = model.classifier[:-3]\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute global min/max for consistent normalization\n",
    "    print(\"Computing global spectrogram statistics...\")\n",
    "    all_mels = []\n",
    "    for i in range(min(100, num_samples)):  # Sample subset for statistics\n",
    "        for j in range(num_channels):\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            all_mels.append(mel.cpu().numpy())\n",
    "    \n",
    "    all_mels = np.concatenate([mel.flatten() for mel in all_mels])\n",
    "    global_min, global_max = np.percentile(all_mels, [1, 99])  # Use percentiles to avoid outliers\n",
    "    \n",
    "    print(f\"Processing {num_samples} samples...\")\n",
    "    for i in range(num_samples):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{num_samples} samples\")\n",
    "            \n",
    "        for j in range(num_channels):\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            \n",
    "            # Use consistent normalization\n",
    "            img = resize_spectrogram(mel, global_min, global_max)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                feat = model(img.unsqueeze(0).to(device))\n",
    "            features[i, j, :] = feat.squeeze().cpu().numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Alternative: Multi-channel processing\n",
    "def process_dataset_multichannel(data, sample_rate=1000):\n",
    "    \"\"\"\n",
    "    Process multiple channels together to capture cross-channel relationships\n",
    "    \"\"\"\n",
    "    num_samples, seq_len, num_channels = data.shape\n",
    "    features = np.zeros((num_samples, 4096))  # Single feature vector per sample\n",
    "    \n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=128,\n",
    "        n_fft=512,\n",
    "        hop_length=256,\n",
    "        win_length=512\n",
    "    ).to(device)\n",
    "    \n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device)\n",
    "    model.classifier = model.classifier[:-3]\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Processing {num_samples} samples with multi-channel approach...\")\n",
    "    for i in range(num_samples):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{num_samples} samples\")\n",
    "        \n",
    "        # Combine multiple channels into RGB image\n",
    "        channel_spectrograms = []\n",
    "        for j in range(min(3, num_channels)):  # Use first 3 channels as RGB\n",
    "            ts = torch.tensor(data[i, :, j], dtype=torch.float32).to(device)\n",
    "            mel = mel_transform(ts)\n",
    "            \n",
    "            # Normalize each channel spectrogram\n",
    "            mel_norm = (mel - mel.min()) / (mel.max() - mel.min() + 1e-8)\n",
    "            mel_resized = torch.nn.functional.interpolate(\n",
    "                mel_norm.unsqueeze(0).unsqueeze(0), \n",
    "                size=(224, 224), \n",
    "                mode='bilinear'\n",
    "            ).squeeze()\n",
    "            channel_spectrograms.append(mel_resized.cpu().numpy())\n",
    "        \n",
    "        # Stack as RGB image\n",
    "        if len(channel_spectrograms) == 1:\n",
    "            rgb_img = np.stack([channel_spectrograms[0]] * 3, axis=0)\n",
    "        elif len(channel_spectrograms) == 2:\n",
    "            rgb_img = np.stack([channel_spectrograms[0], channel_spectrograms[1], channel_spectrograms[0]], axis=0)\n",
    "        else:\n",
    "            rgb_img = np.stack(channel_spectrograms[:3], axis=0)\n",
    "        \n",
    "        img_tensor = torch.tensor(rgb_img, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            feat = model(img_tensor)\n",
    "        features[i, :] = feat.squeeze().cpu().numpy()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f39ba8",
   "metadata": {},
   "source": [
    "# AE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size=4096):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 64), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 8), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 4), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 16), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, input_size), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "# Train autoencoder\n",
    "def train_autoencoder(features, epochs=20, batch_size=128):\n",
    "    x = torch.tensor(features.reshape(-1, 4096), dtype=torch.float32).to(device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=batch_size, shuffle=True)\n",
    "    model = Autoencoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)  # Add weight decay\n",
    "    criterion = nn.MSELoss()  # Try MSE instead of L1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            # Add noise for denoising autoencoder\n",
    "            noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "            outputs = model(noisy_inputs)\n",
    "            loss = criterion(outputs, inputs)  # Reconstruct clean from noisy\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.6f}\")\n",
    "    return model\n",
    "\n",
    "# Compute reconstruction errors\n",
    "def compute_reconstruction_loss(model, data, add_noise=True):\n",
    "    \"\"\"\n",
    "    Compute reconstruction loss per sample (not per segment)\n",
    "    data: shape (n_samples, n_channels, 4096)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    n_samples, n_channels, n_features = data.shape\n",
    "    sample_errors = []\n",
    "    \n",
    "    # Flatten to (n_samples*n_channels, 4096) for batch processing\n",
    "    x = torch.tensor(data.reshape(-1, n_features), dtype=torch.float32).to(next(model.parameters()).device)\n",
    "    loader = DataLoader(TensorDataset(x), batch_size=64)\n",
    "    \n",
    "    all_errors = []\n",
    "    criterion = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            \n",
    "            if add_noise:\n",
    "                noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "                outputs = model(noisy_inputs)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            # Per-segment reconstruction error\n",
    "            segment_errors = criterion(outputs, inputs).mean(dim=1)\n",
    "            all_errors.extend(segment_errors.cpu().numpy())\n",
    "    \n",
    "    # Reshape back to (n_samples, n_channels) and aggregate per sample\n",
    "    all_errors = np.array(all_errors).reshape(n_samples, n_channels)\n",
    "    sample_errors = all_errors.mean(axis=1)  # Average across channels per sample\n",
    "    \n",
    "    return sample_errors\n",
    "\n",
    "# 2. Find best threshold based on F1 score\n",
    "def find_best_threshold(errors, labels):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        f1 = f1_score(labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "def find_best_threshold_using_recall(errors, labels):\n",
    "    best_rec = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        rec = recall_score(labels, preds)\n",
    "        if rec > best_rec:\n",
    "            best_rec = rec\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_rec\n",
    "\n",
    "def find_best_threshold_using_precision(errors, labels):\n",
    "    best_prec = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        prec = precision_score(labels, preds)\n",
    "        if prec > best_prec:\n",
    "            best_prec = prec\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_prec\n",
    "\n",
    "def find_best_threshold_using_accuracy(errors, labels):\n",
    "    best_acc = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.linspace(min(errors), max(errors), 100):\n",
    "        preds = (errors > threshold).astype(int)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_acc\n",
    "\n",
    "\n",
    "def evaluate_on_test_with_threshold_search(model, threshold, X_test, y_test):\n",
    "    \"\"\"\n",
    "    X_test: shape (n_samples, 1, 4096) - already has channel dimension added\n",
    "    y_test: shape (n_samples,)\n",
    "    \"\"\"\n",
    "    # X_test already has shape (n_samples, 1, 4096) from your code\n",
    "    # So we can directly compute reconstruction errors\n",
    "    test_errors = compute_reconstruction_loss(model, X_test)\n",
    "    \n",
    "    # Predict using best threshold\n",
    "    test_preds = (test_errors > threshold).astype(int)\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"Evaluation on Test Set:\")\n",
    "    print(\"Accuracy =\", accuracy_score(y_test, test_preds))\n",
    "    print(\"Precision =\", precision_score(y_test, test_preds))\n",
    "    print(\"Recall =\", recall_score(y_test, test_preds))\n",
    "    print(\"F1 Score =\", f1_score(y_test, test_preds))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7a215",
   "metadata": {},
   "source": [
    "# Comprehensive Anomaly Detection Evaluation Framework\n",
    "\n",
    "This section implements a comprehensive evaluation framework that compares multiple anomaly detection methods and provides statistical analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ed76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Anomaly Detection Comparison\n",
    "def comprehensive_anomaly_detection_evaluation(generated_data, normal_data, faulty_data, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation with multiple anomaly detection methods\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE ANOMALY DETECTION EVALUATION - FEW-SHOT GAN\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Prepare data\n",
    "    all_normal = np.concatenate([generated_data, normal_data], axis=0)\n",
    "    all_data = np.concatenate([all_normal, faulty_data], axis=0)\n",
    "    all_labels = np.concatenate([\n",
    "        np.zeros(len(all_normal)), \n",
    "        np.ones(len(faulty_data))\n",
    "    ])\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Storage for results\n",
    "    methods_results = {\n",
    "        'Reconstruction_Threshold': {'accuracy': [], 'precision': [], 'recall': [], 'f1': []},\n",
    "        'Reconstruction_Percentile': {'accuracy': [], 'precision': [], 'recall': [], 'f1': []},\n",
    "        'OneClass_SVM': {'accuracy': [], 'precision': [], 'recall': [], 'f1': []},\n",
    "        'Isolation_Forest': {'accuracy': [], 'precision': [], 'recall': [], 'f1': []},\n",
    "        'Local_Outlier_Factor': {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    }\n",
    "    \n",
    "    fold_details = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(all_data, all_labels)):\n",
    "        print(f\"\\n--- FOLD {fold + 1}/{cv_folds} ---\")\n",
    "        \n",
    "        # Split data\n",
    "        train_data, test_data = all_data[train_idx], all_data[test_idx]\n",
    "        train_labels, test_labels = all_labels[train_idx], all_labels[test_idx]\n",
    "        \n",
    "        # Get normal training data only\n",
    "        normal_train_data = train_data[train_labels == 0]\n",
    "        \n",
    "        # Process data for feature extraction\n",
    "        processed_normal = process_dataset_multichannel(normal_train_data)\n",
    "        processed_test = process_dataset_multichannel(test_data)\n",
    "        \n",
    "        # Train reconstruction-based model\n",
    "        print(\"Training autoencoder...\")\n",
    "        model = train_autoencoder(processed_normal, epochs=15, batch_size=32)\n",
    "        \n",
    "        # Compute reconstruction errors for test data\n",
    "        test_errors = compute_reconstruction_loss(model, processed_test[:, np.newaxis, :])\n",
    "        \n",
    "        # Method 1: Threshold-based (F1-optimized)\n",
    "        normal_errors = compute_reconstruction_loss(model, processed_normal[:, np.newaxis, :])\n",
    "        threshold, _ = find_best_threshold(\n",
    "            np.concatenate([normal_errors, test_errors[test_labels == 1]]),\n",
    "            np.concatenate([np.zeros(len(normal_errors)), np.ones(np.sum(test_labels == 1))])\n",
    "        )\n",
    "        preds_threshold = (test_errors > threshold).astype(int)\n",
    "        \n",
    "        # Method 2: Percentile-based\n",
    "        percentile_threshold = np.percentile(normal_errors, 95)\n",
    "        preds_percentile = (test_errors > percentile_threshold).astype(int)\n",
    "        \n",
    "        # Method 3: One-Class SVM\n",
    "        oc_svm = OneClassSVM(gamma='scale', nu=0.1)\n",
    "        oc_svm.fit(processed_normal)\n",
    "        preds_svm = (oc_svm.predict(processed_test) == -1).astype(int)\n",
    "        \n",
    "        # Method 4: Isolation Forest\n",
    "        iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "        iso_forest.fit(processed_normal)\n",
    "        preds_iso = (iso_forest.predict(processed_test) == -1).astype(int)\n",
    "        \n",
    "        # Method 5: Local Outlier Factor\n",
    "        lof = LocalOutlierFactor(contamination=0.1, novelty=True)\n",
    "        lof.fit(processed_normal)\n",
    "        preds_lof = (lof.predict(processed_test) == -1).astype(int)\n",
    "        \n",
    "        # Evaluate all methods\n",
    "        methods_preds = {\n",
    "            'Reconstruction_Threshold': preds_threshold,\n",
    "            'Reconstruction_Percentile': preds_percentile,\n",
    "            'OneClass_SVM': preds_svm,\n",
    "            'Isolation_Forest': preds_iso,\n",
    "            'Local_Outlier_Factor': preds_lof\n",
    "        }\n",
    "        \n",
    "        fold_result = {'fold': fold + 1}\n",
    "        \n",
    "        for method_name, preds in methods_preds.items():\n",
    "            acc = accuracy_score(test_labels, preds)\n",
    "            prec = precision_score(test_labels, preds, zero_division=0)\n",
    "            rec = recall_score(test_labels, preds, zero_division=0)\n",
    "            f1 = f1_score(test_labels, preds, zero_division=0)\n",
    "            \n",
    "            methods_results[method_name]['accuracy'].append(acc)\n",
    "            methods_results[method_name]['precision'].append(prec)\n",
    "            methods_results[method_name]['recall'].append(rec)\n",
    "            methods_results[method_name]['f1'].append(f1)\n",
    "            \n",
    "            fold_result[method_name] = {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1}\n",
    "            \n",
    "            print(f\"{method_name:25s} - Acc: {acc:.3f}, Prec: {prec:.3f}, Rec: {rec:.3f}, F1: {f1:.3f}\")\n",
    "        \n",
    "        fold_details.append(fold_result)\n",
    "    \n",
    "    return methods_results, fold_details\n",
    "\n",
    "# Statistical Analysis Function\n",
    "def statistical_analysis(methods_results):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis on cross-validation results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STATISTICAL ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    results_df = []\n",
    "    \n",
    "    for method_name, results in methods_results.items():\n",
    "        for metric in metrics:\n",
    "            values = results[metric]\n",
    "            results_df.append({\n",
    "                'Method': method_name,\n",
    "                'Metric': metric,\n",
    "                'Mean': np.mean(values),\n",
    "                'Std': np.std(values),\n",
    "                'Min': np.min(values),\n",
    "                'Max': np.max(values),\n",
    "                'Median': np.median(values)\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results_df)\n",
    "    \n",
    "    # Display summary table\n",
    "    print(\"\\nSUMMARY STATISTICS:\")\n",
    "    pivot_table = results_df.pivot_table(\n",
    "        index='Method', \n",
    "        columns='Metric', \n",
    "        values=['Mean', 'Std'], \n",
    "        aggfunc='first'\n",
    "    )\n",
    "    print(pivot_table.round(4))\n",
    "    \n",
    "    # Statistical significance tests\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STATISTICAL SIGNIFICANCE TESTS (F1-Score)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    f1_scores = {method: results['f1'] for method, results in methods_results.items()}\n",
    "    \n",
    "    # Perform pairwise t-tests\n",
    "    from scipy.stats import ttest_rel, friedmanchisquare\n",
    "    \n",
    "    # Friedman test for overall difference\n",
    "    f1_values = [scores for scores in f1_scores.values()]\n",
    "    friedman_stat, friedman_p = friedmanchisquare(*f1_values)\n",
    "    print(f\"Friedman Test: χ² = {friedman_stat:.4f}, p-value = {friedman_p:.4f}\")\n",
    "    \n",
    "    if friedman_p < 0.05:\n",
    "        print(\"Significant differences detected between methods.\")\n",
    "        \n",
    "        # Pairwise comparisons\n",
    "        method_names = list(f1_scores.keys())\n",
    "        print(\"\\nPairwise t-test results (F1-Score):\")\n",
    "        for i in range(len(method_names)):\n",
    "            for j in range(i+1, len(method_names)):\n",
    "                stat, p_val = ttest_rel(f1_scores[method_names[i]], f1_scores[method_names[j]])\n",
    "                significance = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "                print(f\"{method_names[i]:25s} vs {method_names[j]:25s}: t={stat:6.3f}, p={p_val:.4f} {significance}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Visualization Functions\n",
    "def create_comprehensive_visualizations(methods_results, fold_details, generated_data):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Performance Comparison Box Plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Few-Shot GAN: Anomaly Detection Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    \n",
    "    for idx, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
    "        ax = axes[idx//2, idx%2]\n",
    "        \n",
    "        data_to_plot = [methods_results[method][metric] for method in methods_results.keys()]\n",
    "        labels = [method.replace('_', ' ') for method in methods_results.keys()]\n",
    "        \n",
    "        bp = ax.boxplot(data_to_plot, labels=labels, patch_artist=True)\n",
    "        ax.set_title(f'{name} Distribution Across Folds', fontweight='bold')\n",
    "        ax.set_ylabel(name)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Color the boxes\n",
    "        colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightpink']\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        \n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Method Ranking Heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create ranking matrix\n",
    "    ranking_data = []\n",
    "    for method in methods_results.keys():\n",
    "        method_means = [np.mean(methods_results[method][metric]) for metric in metrics]\n",
    "        ranking_data.append(method_means)\n",
    "    \n",
    "    ranking_df = pd.DataFrame(\n",
    "        ranking_data, \n",
    "        index=[method.replace('_', ' ') for method in methods_results.keys()],\n",
    "        columns=metric_names\n",
    "    )\n",
    "    \n",
    "    sns.heatmap(ranking_df, annot=True, cmap='RdYlGn', fmt='.3f', center=0.5,\n",
    "                cbar_kws={'label': 'Performance Score'})\n",
    "    plt.title('Few-Shot GAN: Method Performance Heatmap\\n(Higher values = Better performance)', \n",
    "              fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Learning Curves and Fold Performance\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Fold-wise performance\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        for method in methods_results.keys():\n",
    "            values = methods_results[method][metric]\n",
    "            plt.plot(range(1, len(values)+1), values, 'o-', \n",
    "                    label=method.replace('_', ' '), linewidth=2, markersize=6)\n",
    "        \n",
    "        plt.title(f'{metric_names[i]} Across Folds', fontweight='bold')\n",
    "        plt.xlabel('Fold Number')\n",
    "        plt.ylabel(metric_names[i])\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(range(1, 6))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Generated Data Quality Assessment\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Sample some generated data for visualization\n",
    "    n_samples_to_show = min(5, len(generated_data))\n",
    "    sample_indices = np.random.choice(len(generated_data), n_samples_to_show, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        plt.subplot(3, 2, i+1)\n",
    "        \n",
    "        # Show few channels of the generated time series\n",
    "        for ch in range(min(3, generated_data.shape[2])):\n",
    "            plt.plot(generated_data[idx, :, ch], label=f'Channel {ch+1}', alpha=0.7)\n",
    "        \n",
    "        plt.title(f'Generated Sample {i+1}', fontweight='bold')\n",
    "        plt.xlabel('Time Steps')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Summary statistics\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.text(0.1, 0.8, f'Generated Data Summary:', fontweight='bold', fontsize=12, transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.7, f'• Shape: {generated_data.shape}', fontsize=10, transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.6, f'• Mean: {np.mean(generated_data):.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.5, f'• Std: {np.std(generated_data):.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.4, f'• Min: {np.min(generated_data):.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.3, f'• Max: {np.max(generated_data):.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Few-Shot GAN: Generated Data Quality Assessment', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execute comprehensive evaluation\n",
    "print(\"Starting comprehensive evaluation...\")\n",
    "print(f\"Generated data shape: {generated_data.shape}\")\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "methods_results, fold_details = comprehensive_anomaly_detection_evaluation(\n",
    "    generated_data, normal_data, faulty_data, cv_folds=5\n",
    ")\n",
    "\n",
    "# Perform statistical analysis\n",
    "results_df = statistical_analysis(methods_results)\n",
    "\n",
    "# Create visualizations\n",
    "create_comprehensive_visualizations(methods_results, fold_details, generated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaeb581",
   "metadata": {},
   "source": [
    "# Summary and Recommendations\n",
    "\n",
    "## Few-Shot GAN for IoT Anomaly Detection - Key Findings\n",
    "\n",
    "### Model Architecture Enhancements:\n",
    "1. **Enhanced Generator Features:**\n",
    "   - Multi-scale attention mechanisms for better feature learning with limited data\n",
    "   - Progressive upsampling with residual connections for stable training\n",
    "   - Adaptive sequence length adjustment for flexibility\n",
    "\n",
    "2. **Improved Discriminator Design:**\n",
    "   - Multi-scale feature extraction (different kernel sizes) for robust discrimination\n",
    "   - Spectral normalization for training stability\n",
    "   - Dropout regularization to prevent overfitting with few shots\n",
    "\n",
    "3. **Few-Shot Learning Optimizations:**\n",
    "   - Support set training with episodic learning\n",
    "   - Meta-learning capabilities for quick adaptation\n",
    "   - Attention-based feature weighting for relevant pattern extraction\n",
    "\n",
    "### Evaluation Framework Results:\n",
    "The comprehensive evaluation compares multiple anomaly detection approaches:\n",
    "\n",
    "1. **Reconstruction-based Methods:**\n",
    "   - Threshold-based detection (F1-optimized)\n",
    "   - Percentile-based detection (95th percentile)\n",
    "\n",
    "2. **Classical Anomaly Detection:**\n",
    "   - One-Class SVM with RBF kernel\n",
    "   - Isolation Forest with contamination estimation\n",
    "   - Local Outlier Factor with novelty detection\n",
    "\n",
    "3. **Statistical Analysis:**\n",
    "   - Cross-validation with 5 folds for robust evaluation\n",
    "   - Friedman test for statistical significance\n",
    "   - Pairwise t-tests for method comparison\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **For Few-Shot Scenarios:**\n",
    "   - Use attention mechanisms to focus on discriminative features\n",
    "   - Implement episodic training with support/query sets\n",
    "   - Consider meta-learning approaches for rapid adaptation\n",
    "\n",
    "2. **Model Selection:**\n",
    "   - Monitor the trade-off between reconstruction and adversarial losses\n",
    "   - Use ensemble methods combining multiple detection approaches\n",
    "   - Validate on diverse IoT datasets for generalization\n",
    "\n",
    "3. **Training Strategies:**\n",
    "   - Start with pre-trained features when available\n",
    "   - Use progressive growing for sequence length adaptation\n",
    "   - Implement curriculum learning from simple to complex patterns\n",
    "\n",
    "4. **Deployment Considerations:**\n",
    "   - Few-shot GANs are particularly suitable for rare fault scenarios\n",
    "   - Monitor model performance degradation over time\n",
    "   - Implement active learning for continuous model improvement\n",
    "\n",
    "### Performance Expectations:\n",
    "Few-Shot GANs excel in scenarios with limited training data but may require careful hyperparameter tuning and architecture design to achieve optimal performance in IoT anomaly detection tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
