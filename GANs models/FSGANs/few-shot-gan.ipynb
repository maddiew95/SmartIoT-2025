{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio, torchvision.transforms as transforms, matplotlib.pyplot as plt, torch.nn as nn, torch.optim as optim, numpy as np\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from ad_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "cuda1 = torch.device(\"cuda:1\")\n",
    "device = cuda1\n",
    "print(torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"No GPU available\")\n",
    "\n",
    "data = np.load(\"../../hvcm/RFQ.npy\", allow_pickle=True)\n",
    "label = np.load(\"../../hvcm/RFQ_labels.npy\", allow_pickle=True)\n",
    "label = label[:, 1]  # Assuming the second column is the label\n",
    "label = (label == \"Fault\").astype(int)  # Convert to binary labels\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data.reshape(-1, data.shape[-1])).reshape(data.shape)\n",
    "\n",
    "normal_data = data[label == 0]\n",
    "faulty_data = data[label == 1]\n",
    "\n",
    "normal_label = label[label == 0]\n",
    "faulty_label = label[label == 1]\n",
    "\n",
    "X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(normal_data, normal_label, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train_faulty, X_test_faulty, y_train_faulty, y_test_faulty = train_test_split(faulty_data, faulty_label, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14127475",
   "metadata": {},
   "source": [
    "# Few-Shot GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Attention mechanism for Few-Shot learning\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, attention_dim=64):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, attention_dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(attention_dim, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attention_weights = self.attention(x)\n",
    "        return x * attention_weights\n",
    "\n",
    "# Enhanced Few-Shot Generator with Attention and Residual Connections\n",
    "class EnhancedFewShotGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, channels=14, seq_len=4500):\n",
    "        super(EnhancedFewShotGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.channels = channels\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        # Start with a smaller sequence length and upsample\n",
    "        self.init_seq_len = seq_len // 32  # More aggressive downsampling\n",
    "        \n",
    "        # Enhanced initial projection with batch normalization\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256 * self.init_seq_len),\n",
    "            nn.BatchNorm1d(256 * self.init_seq_len),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Progressive upsampling with attention and residual connections\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            # Block 1: 256 -> 128 channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                AttentionBlock(128)\n",
    "            ),\n",
    "            # Block 2: 128 -> 64 channels  \n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                AttentionBlock(64)\n",
    "            ),\n",
    "            # Block 3: 64 -> 32 channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ),\n",
    "            # Block 4: 32 -> 16 channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ),\n",
    "            # Final block: 16 -> channels\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(16, channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 256, self.init_seq_len)\n",
    "        \n",
    "        # Progressive upsampling with skip connections\n",
    "        for i, block in enumerate(self.conv_blocks):\n",
    "            out = block(out)\n",
    "        \n",
    "        # Ensure exact sequence length through interpolation if needed\n",
    "        if out.size(2) != self.seq_len:\n",
    "            out = nn.functional.interpolate(out, size=self.seq_len, mode='linear', align_corners=False)\n",
    "        \n",
    "        return out  # Shape: (batch, 14, 4500)\n",
    "\n",
    "# Enhanced Few-Shot Discriminator with Multi-Scale Features\n",
    "class EnhancedFewShotDiscriminator(nn.Module):\n",
    "    def __init__(self, channels=14, seq_len=4500):\n",
    "        super(EnhancedFewShotDiscriminator, self).__init__()\n",
    "        \n",
    "        # Multi-scale feature extraction\n",
    "        self.scale1_conv = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(channels, 32, kernel_size=3, stride=1, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.utils.spectral_norm(nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.scale2_conv = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(channels, 32, kernel_size=7, stride=1, padding=3)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.utils.spectral_norm(nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Feature fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        # Further processing\n",
    "        self.model = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.utils.spectral_norm(nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.utils.spectral_norm(nn.Linear(512, 256)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.utils.spectral_norm(nn.Linear(256, 1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Multi-scale feature extraction\n",
    "        scale1_features = self.scale1_conv(x)\n",
    "        scale2_features = self.scale2_conv(x)\n",
    "        \n",
    "        # Concatenate multi-scale features\n",
    "        multi_scale_features = torch.cat([scale1_features, scale2_features], dim=1)\n",
    "        \n",
    "        # Fusion and classification\n",
    "        fused_features = self.fusion(multi_scale_features)\n",
    "        output = self.model(fused_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class FewShot1DDataset(Dataset):\n",
    "    def __init__(self, data, labels=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape [n_samples, 4500, 14]\n",
    "            labels: numpy array of shape [n_samples] (optional)\n",
    "        \"\"\"\n",
    "        # Transpose to (n_samples, 14, 4500) for Conv1d\n",
    "        self.data = torch.tensor(data.transpose(0, 2, 1), dtype=torch.float32)\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]  # Shape: (14, 4500)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return sample, label\n",
    "        return sample, 0\n",
    "\n",
    "# Enhanced training function with few-shot learning capabilities\n",
    "def train_enhanced_few_shot_gan(normal_data, device, epochs=100, batch_size=32, lr_g=1e-4, lr_d=2e-4):\n",
    "    \"\"\"\n",
    "    Enhanced Few-Shot GAN training with improved stability and attention mechanisms\n",
    "    \"\"\"\n",
    "    print(f\"Training Enhanced Few-Shot GAN on data shape: {normal_data.shape}\")\n",
    "    \n",
    "    # Data loading\n",
    "    dataset = FewShot1DDataset(normal_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Initialize enhanced models\n",
    "    latent_dim = 100\n",
    "    num_channels = normal_data.shape[-1]\n",
    "    seq_length = normal_data.shape[1]\n",
    "    \n",
    "    generator = EnhancedFewShotGenerator(latent_dim=latent_dim, channels=num_channels, seq_len=seq_length).to(device)\n",
    "    discriminator = EnhancedFewShotDiscriminator(channels=num_channels, seq_len=seq_length).to(device)\n",
    "\n",
    "    # Xavier/He initialization for better stability\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d, nn.Linear)):\n",
    "            nn.init.xavier_normal_(m.weight, gain=0.02)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    generator.apply(init_weights)\n",
    "    discriminator.apply(init_weights)\n",
    "\n",
    "    # Optimizers with different learning rates for stability\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "\n",
    "    # Learning rate schedulers\n",
    "    scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, patience=20, factor=0.8)\n",
    "    scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, patience=20, factor=0.8)\n",
    "\n",
    "    # Enhanced loss function with label smoothing\n",
    "    def adversarial_loss_smooth(pred, target_is_real, smoothing=0.1):\n",
    "        if target_is_real:\n",
    "            target = torch.ones_like(pred) * (1.0 - smoothing) + smoothing * torch.rand_like(pred)\n",
    "        else:\n",
    "            target = torch.zeros_like(pred) + smoothing * torch.rand_like(pred)\n",
    "        return nn.BCELoss()(pred, target)\n",
    "\n",
    "    # Training history\n",
    "    g_losses, d_losses = [], []\n",
    "    \n",
    "    print(\"Starting Enhanced Few-Shot GAN training...\")\n",
    "    print(f\"Generator LR: {lr_g}, Discriminator LR: {lr_d}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_g_loss, epoch_d_loss = 0, 0\n",
    "        \n",
    "        for i, (real_samples, _) in enumerate(dataloader):\n",
    "            real_samples = real_samples.to(device)  # Shape: (batch, 14, 4500)\n",
    "            batch_size_actual = real_samples.size(0)\n",
    "            \n",
    "            # Add noise to real samples for robustness\n",
    "            noisy_real = real_samples + 0.05 * torch.randn_like(real_samples)\n",
    "            \n",
    "            # ========================\n",
    "            # Train Discriminator\n",
    "            # ========================\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real samples\n",
    "            real_pred = discriminator(noisy_real)\n",
    "            d_real_loss = adversarial_loss_smooth(real_pred, True)\n",
    "            \n",
    "            # Fake samples\n",
    "            z = torch.randn(batch_size_actual, latent_dim, device=device)\n",
    "            fake_samples = generator(z).detach()\n",
    "            fake_pred = discriminator(fake_samples)\n",
    "            d_fake_loss = adversarial_loss_smooth(fake_pred, False)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 0.5)\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # ========================\n",
    "            # Train Generator\n",
    "            # ========================\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake samples\n",
    "            z = torch.randn(batch_size_actual, latent_dim, device=device)\n",
    "            fake_samples = generator(z)\n",
    "            fake_pred = discriminator(fake_samples)\n",
    "            \n",
    "            # Generator loss (want discriminator to classify fake as real)\n",
    "            g_loss = adversarial_loss_smooth(fake_pred, True)\n",
    "            g_loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(generator.parameters(), 0.5)\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                      f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "\n",
    "        # Store average losses per epoch\n",
    "        avg_g_loss = epoch_g_loss / len(dataloader)\n",
    "        avg_d_loss = epoch_d_loss / len(dataloader)\n",
    "        g_losses.append(avg_g_loss)\n",
    "        d_losses.append(avg_d_loss)\n",
    "\n",
    "        # Update learning rates\n",
    "        scheduler_G.step(avg_g_loss)\n",
    "        scheduler_D.step(avg_d_loss)\n",
    "\n",
    "        # Enhanced stability monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            monitor_gan_stability(g_losses, d_losses, window=10)\n",
    "    \n",
    "    print(\"Enhanced Few-Shot GAN training completed!\")\n",
    "    return generator, discriminator, g_losses, d_losses\n",
    "\n",
    "def generate_samples(generator, num_samples, latent_dim=100):\n",
    "    \"\"\"\n",
    "    Generate samples using the trained generator\n",
    "    Returns data in shape (num_samples, 4500, 14)\n",
    "    \"\"\"\n",
    "    device = next(generator.parameters()).device\n",
    "    generator.eval()\n",
    "    \n",
    "    batch_size = 16\n",
    "    all_samples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            current_batch_size = end - start\n",
    "            \n",
    "            z = torch.randn(current_batch_size, latent_dim, device=device)\n",
    "            batch_samples = generator(z)  # Shape: (batch, 14, 4500)\n",
    "            all_samples.append(batch_samples.cpu())\n",
    "    \n",
    "    generated_data = torch.cat(all_samples, dim=0).numpy()\n",
    "    \n",
    "    # Transpose back to (n_samples, 4500, 14)\n",
    "    generated_data = generated_data.transpose(0, 2, 1)\n",
    "    \n",
    "    return generated_data\n",
    "\n",
    "# Enhanced monitoring with more detailed analysis\n",
    "def monitor_gan_stability(g_losses, d_losses, window=10):\n",
    "    \"\"\"\n",
    "    Enhanced GAN training stability monitoring\n",
    "    \"\"\"\n",
    "    if len(g_losses) < window:\n",
    "        return\n",
    "    \n",
    "    # Recent losses\n",
    "    recent_g = np.mean(g_losses[-window:])\n",
    "    recent_d = np.mean(d_losses[-window:])\n",
    "    \n",
    "    # Loss ratio (should be roughly balanced)\n",
    "    ratio = recent_g / (recent_d + 1e-8)\n",
    "    \n",
    "    # Loss variance (should be stable, not oscillating wildly)\n",
    "    g_var = np.var(g_losses[-window:])\n",
    "    d_var = np.var(d_losses[-window:])\n",
    "    \n",
    "    # Loss trend analysis\n",
    "    if len(g_losses) >= window * 2:\n",
    "        g_trend = np.mean(g_losses[-window:]) - np.mean(g_losses[-window*2:-window])\n",
    "        d_trend = np.mean(d_losses[-window:]) - np.mean(d_losses[-window*2:-window])\n",
    "    else:\n",
    "        g_trend = d_trend = 0\n",
    "    \n",
    "    print(f\"G/D Ratio: {ratio:.3f} | G_var: {g_var:.4f} | D_var: {d_var:.4f}\")\n",
    "    print(f\"G_trend: {g_trend:+.4f} | D_trend: {d_trend:+.4f}\")\n",
    "    \n",
    "    # Enhanced stability warnings\n",
    "    if ratio > 5:\n",
    "        print(\"‚ö†Ô∏è  Generator significantly overpowering Discriminator\")\n",
    "        print(\"   üí° Consider: Lower G learning rate or train D more frequently\")\n",
    "    elif ratio < 0.2:\n",
    "        print(\"‚ö†Ô∏è  Discriminator significantly overpowering Generator\")\n",
    "        print(\"   üí° Consider: Lower D learning rate or add noise to real data\")\n",
    "    elif g_var > 1.0 or d_var > 1.0:\n",
    "        print(\"‚ö†Ô∏è  High variance - unstable training detected\")\n",
    "        print(\"   üí° Consider: Lower learning rates or gradient clipping\")\n",
    "    elif abs(g_trend) > 0.5 or abs(d_trend) > 0.5:\n",
    "        print(\"‚ö†Ô∏è  Significant loss trends detected\")\n",
    "        print(\"   üí° Consider: Learning rate scheduling or early stopping\")\n",
    "    else:\n",
    "        print(\"‚úÖ Training appears stable and balanced\")\n",
    "\n",
    "# Enhanced visualization\n",
    "def plot_enhanced_training_curves(g_losses, d_losses):\n",
    "    \"\"\"\n",
    "    Plot enhanced training curves with additional analysis\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(g_losses, label='Generator Loss', alpha=0.7)\n",
    "    axes[0, 0].plot(d_losses, label='Discriminator Loss', alpha=0.7)\n",
    "    axes[0, 0].set_title('Training Losses')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss ratio\n",
    "    ratios = [g/(d+1e-8) for g, d in zip(g_losses, d_losses)]\n",
    "    axes[0, 1].plot(ratios, color='green', alpha=0.7)\n",
    "    axes[0, 1].axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Ideal Ratio')\n",
    "    axes[0, 1].set_title('Generator/Discriminator Loss Ratio')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('G_loss / D_loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Moving averages\n",
    "    window = 10\n",
    "    if len(g_losses) >= window:\n",
    "        g_ma = pd.Series(g_losses).rolling(window=window).mean()\n",
    "        d_ma = pd.Series(d_losses).rolling(window=window).mean()\n",
    "        \n",
    "        axes[1, 0].plot(g_ma, label=f'Generator MA({window})', alpha=0.7)\n",
    "        axes[1, 0].plot(d_ma, label=f'Discriminator MA({window})', alpha=0.7)\n",
    "        axes[1, 0].set_title('Moving Average Losses')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Loss')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss variance\n",
    "    if len(g_losses) >= window:\n",
    "        g_var = pd.Series(g_losses).rolling(window=window).var()\n",
    "        d_var = pd.Series(d_losses).rolling(window=window).var()\n",
    "        \n",
    "        axes[1, 1].plot(g_var, label=f'Generator Var({window})', alpha=0.7)\n",
    "        axes[1, 1].plot(d_var, label=f'Discriminator Var({window})', alpha=0.7)\n",
    "        axes[1, 1].set_title('Loss Variance (Stability Indicator)')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Variance')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dd307",
   "metadata": {},
   "source": [
    "# Few-Shot GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0267ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention1D(nn.Module):\n",
    "    \"\"\"Self-attention module for capturing long-range dependencies\"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention1D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.query = nn.Conv1d(in_channels, in_channels // 8, 1)\n",
    "        self.key = nn.Conv1d(in_channels, in_channels // 8, 1)\n",
    "        self.value = nn.Conv1d(in_channels, in_channels, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channels, length = x.size()\n",
    "        \n",
    "        # Generate query, key, value\n",
    "        q = self.query(x).view(batch_size, -1, length).permute(0, 2, 1)\n",
    "        k = self.key(x).view(batch_size, -1, length)\n",
    "        v = self.value(x).view(batch_size, -1, length)\n",
    "        \n",
    "        # Attention calculation\n",
    "        attention = torch.bmm(q, k)\n",
    "        attention = self.softmax(attention)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        out = torch.bmm(v, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, channels, length)\n",
    "        \n",
    "        # Residual connection with learnable weight\n",
    "        return self.gamma * out + x\n",
    "\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    \"\"\"Residual block for better gradient flow\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return F.relu(out + residual)\n",
    "\n",
    "class ImprovedFewShotGenerator(nn.Module):\n",
    "    \"\"\"Enhanced generator with residual connections, self-attention, and progressive upsampling\"\"\"\n",
    "    def __init__(self, latent_dim=100, output_channels=14, target_length=4500):\n",
    "        super(ImprovedFewShotGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.target_length = target_length\n",
    "        \n",
    "        # Initial projection - start with very small length\n",
    "        self.initial_length = 72  # Will be upsampled to 4500\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256 * self.initial_length),\n",
    "            nn.BatchNorm1d(256 * self.initial_length),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Progressive upsampling with residual blocks\n",
    "        self.upsample_blocks = nn.ModuleList([\n",
    "            # 72 -> 144\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(256, 256, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(True),\n",
    "                ResidualBlock1D(256)\n",
    "            ),\n",
    "            # 144 -> 288\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(256, 128, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(True),\n",
    "                ResidualBlock1D(128)\n",
    "            ),\n",
    "            # 288 -> 576\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(128, 128, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(True),\n",
    "                ResidualBlock1D(128)\n",
    "            ),\n",
    "            # 576 -> 1152\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(128, 64, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(True),\n",
    "                ResidualBlock1D(64)\n",
    "            ),\n",
    "            # 1152 -> 2304\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose1d(64, 64, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(True),\n",
    "                ResidualBlock1D(64)\n",
    "            ),\n",
    "        ])\n",
    "        \n",
    "        # Self-attention for long-range dependencies\n",
    "        self.attention = SelfAttention1D(64)\n",
    "        \n",
    "        # Final upsampling to exact target length\n",
    "        self.final_upsample = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 32, 4, stride=2, padding=1),  # 2304 -> 4608\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, output_channels, 3, padding=1),  # Channel adjustment\n",
    "            nn.Tanh()  # Output activation\n",
    "        )\n",
    "        \n",
    "        # Learnable cropping/padding to get exact length\n",
    "        self.length_adjuster = nn.Conv1d(output_channels, output_channels, 1)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Project latent vector\n",
    "        x = self.fc(z)\n",
    "        x = x.view(z.size(0), 256, self.initial_length)\n",
    "        \n",
    "        # Progressive upsampling with residual connections\n",
    "        for upsample_block in self.upsample_blocks:\n",
    "            x = upsample_block(x)\n",
    "        \n",
    "        # Apply self-attention\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        # Final upsampling\n",
    "        x = self.final_upsample(x)\n",
    "        \n",
    "        # Adjust to exact target length\n",
    "        current_length = x.size(-1)\n",
    "        if current_length > self.target_length:\n",
    "            # Crop to target length\n",
    "            start_idx = (current_length - self.target_length) // 2\n",
    "            x = x[:, :, start_idx:start_idx + self.target_length]\n",
    "        elif current_length < self.target_length:\n",
    "            # Pad to target length\n",
    "            pad_size = self.target_length - current_length\n",
    "            x = F.pad(x, (pad_size // 2, pad_size - pad_size // 2))\n",
    "        \n",
    "        # Final channel adjustment\n",
    "        x = self.length_adjuster(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ImprovedFewShotDiscriminator(nn.Module):\n",
    "    \"\"\"Enhanced discriminator with spectral normalization and progressive downsampling\"\"\"\n",
    "    def __init__(self, input_channels=14):\n",
    "        super(ImprovedFewShotDiscriminator, self).__init__()\n",
    "        \n",
    "        # Progressive downsampling with spectral normalization\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            # 4500 -> 2250\n",
    "            nn.Sequential(\n",
    "                nn.utils.spectral_norm(nn.Conv1d(input_channels, 32, 4, stride=2, padding=1)),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            # 2250 -> 1125\n",
    "            nn.Sequential(\n",
    "                nn.utils.spectral_norm(nn.Conv1d(32, 64, 4, stride=2, padding=1)),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            # 1125 -> 562\n",
    "            nn.Sequential(\n",
    "                nn.utils.spectral_norm(nn.Conv1d(64, 128, 4, stride=2, padding=1)),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout(0.3)\n",
    "            ),\n",
    "            # 562 -> 281\n",
    "            nn.Sequential(\n",
    "                nn.utils.spectral_norm(nn.Conv1d(128, 256, 4, stride=2, padding=1)),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout(0.3)\n",
    "            ),\n",
    "            # 281 -> 140\n",
    "            nn.Sequential(\n",
    "                nn.utils.spectral_norm(nn.Conv1d(256, 512, 4, stride=2, padding=1)),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout(0.4)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Self-attention for better feature extraction\n",
    "        self.attention = SelfAttention1D(512)\n",
    "        \n",
    "        # Final classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.utils.spectral_norm(nn.Linear(512, 256)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.utils.spectral_norm(nn.Linear(256, 1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, return_features=False):\n",
    "        features = []\n",
    "        \n",
    "        # Progressive downsampling\n",
    "        for conv_block in self.conv_blocks:\n",
    "            x = conv_block(x)\n",
    "            if return_features:\n",
    "                features.append(x)\n",
    "        \n",
    "        # Apply self-attention\n",
    "        x = self.attention(x)\n",
    "        if return_features:\n",
    "            features.append(x)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.classifier(x)\n",
    "        \n",
    "        if return_features:\n",
    "            return output, features\n",
    "        return output\n",
    "\n",
    "def feature_matching_loss(real_features, fake_features):\n",
    "    \"\"\"Feature matching loss to improve sample quality\"\"\"\n",
    "    loss = 0\n",
    "    for real_feat, fake_feat in zip(real_features, fake_features):\n",
    "        loss += nn.MSELoss()(fake_feat.mean(0), real_feat.mean(0))\n",
    "    return loss\n",
    "\n",
    "def gradient_penalty(discriminator, real_samples, fake_samples, device):\n",
    "    \"\"\"Gradient penalty for improved training stability\"\"\"\n",
    "    batch_size = real_samples.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, 1).expand_as(real_samples).to(device)\n",
    "    \n",
    "    interpolated = alpha * real_samples + (1 - alpha) * fake_samples\n",
    "    interpolated.requires_grad_(True)\n",
    "    \n",
    "    d_interpolated = discriminator(interpolated)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolated,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(d_interpolated),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "def train_improved_few_shot_gan(X_train, epochs=200, batch_size=32, latent_dim=100, \n",
    "                               lr_g=0.0001, lr_d=0.0002, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train Few-Shot GAN with all improvements for better FID score\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting Enhanced Few-Shot GAN Training for Better FID Score\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Data loading\n",
    "    dataset = FewShot1DDataset(X_train)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # Initialize improved models\n",
    "    generator = ImprovedFewShotGenerator(latent_dim=latent_dim).to(device)\n",
    "    discriminator = ImprovedFewShotDiscriminator().to(device)\n",
    "    \n",
    "    # Optimizers with improved settings\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr_g, betas=(0.0, 0.9))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.0, 0.9))\n",
    "    \n",
    "    # Loss function\n",
    "    adversarial_loss = nn.BCELoss()\n",
    "    \n",
    "    # Training tracking\n",
    "    g_losses, d_losses = [], []\n",
    "    feature_losses, gp_losses = [], []\n",
    "    \n",
    "    print(f\"üìä Training Configuration:\")\n",
    "    print(f\"   ‚Ä¢ Generator Parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"   ‚Ä¢ Discriminator Parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "    print(f\"   ‚Ä¢ Dataset Size: {len(dataset):,} samples\")\n",
    "    print(f\"   ‚Ä¢ Batch Size: {batch_size}\")\n",
    "    print(f\"   ‚Ä¢ Learning Rates: G={lr_g}, D={lr_d}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_g_loss, epoch_d_loss = 0, 0\n",
    "        epoch_feature_loss, epoch_gp_loss = 0, 0\n",
    "        \n",
    "        for i, (real_samples, _) in enumerate(dataloader):\n",
    "            real_samples = real_samples.to(device)\n",
    "            batch_size_current = real_samples.size(0)\n",
    "            \n",
    "            # ========================\n",
    "            # Train Discriminator (2 times per generator update)\n",
    "            # ========================\n",
    "            for _ in range(2):\n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # Real samples with label smoothing\n",
    "                real_labels = torch.ones(batch_size_current, 1, device=device) * 0.9\n",
    "                real_pred = discriminator(real_samples)\n",
    "                real_loss = adversarial_loss(real_pred, real_labels)\n",
    "                \n",
    "                # Fake samples\n",
    "                z = torch.randn(batch_size_current, latent_dim, device=device)\n",
    "                fake_samples = generator(z).detach()\n",
    "                fake_labels = torch.zeros(batch_size_current, 1, device=device) * 0.1\n",
    "                fake_pred = discriminator(fake_samples)\n",
    "                fake_loss = adversarial_loss(fake_pred, fake_labels)\n",
    "                \n",
    "                # Gradient penalty\n",
    "                gp = gradient_penalty(discriminator, real_samples, fake_samples, device)\n",
    "                \n",
    "                # Total discriminator loss\n",
    "                d_loss = real_loss + fake_loss + 10.0 * gp\n",
    "                d_loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 0.5)\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                epoch_gp_loss += gp.item()\n",
    "            \n",
    "            # ========================\n",
    "            # Train Generator with Feature Matching\n",
    "            # ========================\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake samples\n",
    "            z = torch.randn(batch_size_current, latent_dim, device=device)\n",
    "            fake_samples = generator(z)\n",
    "            \n",
    "            # Get discriminator predictions and features\n",
    "            fake_pred, fake_features = discriminator(fake_samples, return_features=True)\n",
    "            _, real_features = discriminator(real_samples, return_features=True)\n",
    "            \n",
    "            # Adversarial loss\n",
    "            valid_labels = torch.ones(batch_size_current, 1, device=device)\n",
    "            adv_loss = adversarial_loss(fake_pred, valid_labels)\n",
    "            \n",
    "            # Feature matching loss\n",
    "            fm_loss = feature_matching_loss(real_features, fake_features)\n",
    "            \n",
    "            # Combined generator loss\n",
    "            g_loss = adv_loss + 10.0 * fm_loss\n",
    "            g_loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(generator.parameters(), 0.5)\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # Track losses\n",
    "            epoch_g_loss += adv_loss.item()\n",
    "            epoch_d_loss += (real_loss.item() + fake_loss.item()) / 2\n",
    "            epoch_feature_loss += fm_loss.item()\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                print(f\"[Epoch {epoch+1:3d}/{epochs}] [Batch {i:3d}/{len(dataloader)}] \"\n",
    "                      f\"[D: {d_loss.item():.4f}] [G: {adv_loss.item():.4f}] \"\n",
    "                      f\"[FM: {fm_loss.item():.4f}] [GP: {gp.item():.4f}]\")\n",
    "        \n",
    "        # Store average losses per epoch\n",
    "        g_losses.append(epoch_g_loss / len(dataloader))\n",
    "        d_losses.append(epoch_d_loss / len(dataloader))\n",
    "        feature_losses.append(epoch_feature_loss / len(dataloader))\n",
    "        gp_losses.append(epoch_gp_loss / (len(dataloader) * 2))\n",
    "        \n",
    "        # Enhanced monitoring every 20 epochs\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"\\n{'='*15} Epoch {epoch+1} Summary {'='*15}\")\n",
    "            print(f\"üìà Avg Generator Loss: {g_losses[-1]:.4f}\")\n",
    "            print(f\"üìâ Avg Discriminator Loss: {d_losses[-1]:.4f}\")\n",
    "            print(f\"üéØ Avg Feature Matching Loss: {feature_losses[-1]:.4f}\")\n",
    "            print(f\"‚öñÔ∏è  Avg Gradient Penalty: {gp_losses[-1]:.4f}\")\n",
    "            \n",
    "            # Generate samples for quality check\n",
    "            with torch.no_grad():\n",
    "                z_test = torch.randn(32, latent_dim, device=device)\n",
    "                test_samples = generator(z_test)\n",
    "                \n",
    "                # Basic quality metrics\n",
    "                sample_mean = test_samples.mean().item()\n",
    "                sample_std = test_samples.std().item()\n",
    "                sample_range = (test_samples.max() - test_samples.min()).item()\n",
    "                \n",
    "                print(f\"üìä Generated Sample Stats:\")\n",
    "                print(f\"   ‚Ä¢ Mean: {sample_mean:.4f}\")\n",
    "                print(f\"   ‚Ä¢ Std: {sample_std:.4f}\")\n",
    "                print(f\"   ‚Ä¢ Range: {sample_range:.4f}\")\n",
    "            \n",
    "            print(\"=\" * 50)\n",
    "    \n",
    "    return generator, discriminator, g_losses, d_losses, feature_losses, gp_losses\n",
    "\n",
    "print(\"‚úÖ Enhanced training function ready!\")\n",
    "\n",
    "# Train the improved Few-Shot GAN\n",
    "print(\"üîÑ Training Enhanced Few-Shot GAN with Improved Architecture...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train with shorter epochs first to test\n",
    "enhanced_generator, enhanced_discriminator, enh_g_losses, enh_d_losses, enh_fm_losses, enh_gp_losses = train_improved_few_shot_gan(\n",
    "    X_train_normal, \n",
    "    epochs=200,  # Start with 50 epochs for comparison\n",
    "    batch_size=32,\n",
    "    latent_dim=100,\n",
    "    lr_g=0.005,\n",
    "    lr_d=0.0002,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ee542",
   "metadata": {},
   "source": [
    "# Generate and Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6809752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "num_samples = len(X_train_normal)  # Number of samples to generate\n",
    "generated_data = generate_samples(enhanced_generator, num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# FID SCORE EVALUATION\n",
    "# ===============================\n",
    "\n",
    "# Test the simplified FID calculation\n",
    "print(\"Testing simplified FID calculation...\")\n",
    "\n",
    "# Use smaller subsets for testing\n",
    "test_real = X_train_normal[:100]  # Use 100 samples for testing\n",
    "test_generated = generated_data[:100]\n",
    "\n",
    "print(f\"Test real data shape: {test_real.shape}\")\n",
    "print(f\"Test generated data shape: {test_generated.shape}\")\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid_score(\n",
    "    real_data=test_real,\n",
    "    fake_data=test_generated,\n",
    "    device=device,\n",
    "    sample_rate=1000,\n",
    ")\n",
    "\n",
    "if fid_score is not None:\n",
    "    print(f\"\\nüéâ SUCCESS! FID Score: {fid_score:.4f}\")\n",
    "    \n",
    "    # Interpret the score\n",
    "    if fid_score < 10:\n",
    "        quality = \"Excellent\"\n",
    "    elif fid_score < 25:\n",
    "        quality = \"Good\"\n",
    "    elif fid_score < 50:\n",
    "        quality = \"Fair\"\n",
    "    elif fid_score < 100:\n",
    "        quality = \"Poor\"\n",
    "    else:\n",
    "        quality = \"Very Poor\"\n",
    "    \n",
    "    print(f\"Quality Assessment: {quality}\")\n",
    "else:\n",
    "    print(\"‚ùå FID calculation failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_comprehensive_cross_validation_experiment(X_test_normal, X_test_faulty, device, generated_data, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c1261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
